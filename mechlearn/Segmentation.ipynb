{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cpu,floatX=float32\"\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track = pickle.load(open(\"mario_track_1.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def thresholds(vals, t_window=5):\n",
    "    last_diff = 0\n",
    "    last_diff_t = 0\n",
    "    max_v = min(vals)\n",
    "    min_v = max(vals)\n",
    "    thresholds = set([0, min_v, max_v])\n",
    "    for t, v in enumerate(vals):\n",
    "        if (t - last_diff_t) == t_window:\n",
    "            thresholds.add(last_diff)\n",
    "        if v != last_diff:\n",
    "            last_diff = v\n",
    "            last_diff_t = t\n",
    "    return thresholds\n",
    "\n",
    "axis = 2\n",
    "window = 3\n",
    "\n",
    "velocities = track[1:,axis]-track[:-1,axis] \n",
    "print velocities\n",
    "print np.convolve(velocities, np.ones(window)/window, mode='valid')\n",
    "\n",
    "thresholds(velocities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def samey_intervals(vals, t_window=5):\n",
    "    last_diff = 0\n",
    "    last_diff_t = 0\n",
    "    intervals = []\n",
    "    for t, v in enumerate(vals):\n",
    "        if ((t - last_diff_t) >= t_window) and v != last_diff:\n",
    "            intervals.append(last_diff_t)\n",
    "            intervals.append(t-1)\n",
    "            intervals.append(t)\n",
    "        if v != last_diff:\n",
    "            last_diff = v\n",
    "            last_diff_t = t\n",
    "    return intervals\n",
    "\n",
    "axis = 2\n",
    "window = 2\n",
    "\n",
    "velocities = track[1:,axis]-track[:-1,axis] \n",
    "smoothed = scipy.ndimage.filters.convolve1d(velocities, np.ones(window)/window)\n",
    "\n",
    "print velocities\n",
    "print smoothed\n",
    "\n",
    "print samey_intervals(velocities)\n",
    "print samey_intervals(smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def zero_crossings(vals):\n",
    "    sign_intervals = []\n",
    "    last_sign_change = 0\n",
    "    vsigns = np.sign(vals)\n",
    "    last_sign = vsigns[0]\n",
    "    for t, v in enumerate(vsigns):\n",
    "        if last_sign == 0:\n",
    "            last_sign = v\n",
    "        elif v == 0 or v == last_sign:\n",
    "            continue\n",
    "        elif v != last_sign:\n",
    "            sign_intervals.append(last_sign_change)\n",
    "            sign_intervals.append(t-1)\n",
    "            sign_intervals.append(t)\n",
    "            last_sign = v\n",
    "            last_sign_change = t\n",
    "    if t - 1 != last_sign_change:\n",
    "        sign_intervals.append(last_sign_change)\n",
    "        sign_intervals.append(t)\n",
    "    return sign_intervals\n",
    "\n",
    "axis = 2\n",
    "window = 2\n",
    "\n",
    "velocities = track[1:,axis]-track[:-1,axis] \n",
    "smoothed = scipy.ndimage.filters.convolve1d(velocities, np.ones(window)/window)\n",
    "\n",
    "print velocities\n",
    "print smoothed\n",
    "\n",
    "print zero_crossings(velocities)\n",
    "print zero_crossings(smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axis = 2\n",
    "\n",
    "velocities = track[1:,axis]-track[:-1,axis] \n",
    "\n",
    "same_window = 10\n",
    "\n",
    "switch_points = set(zero_crossings(velocities))\n",
    "print sorted(switch_points)\n",
    "\n",
    "smoothed_points = set(samey_intervals(velocities,t_window=same_window))\n",
    "print sorted(smoothed_points)\n",
    "for w in range(2,6):\n",
    "    smoothed = scipy.ndimage.filters.convolve1d(velocities, np.ones(w)/w)\n",
    "    #print smoothed\n",
    "    plt.plot(smoothed)\n",
    "    \n",
    "    points = samey_intervals(smoothed,t_window=same_window)\n",
    "    plt.plot(np.array(points),smoothed[np.array(points,dtype='int')],'rx')\n",
    "    plt.show()\n",
    "    \n",
    "    pts = set()\n",
    "    for pt in smoothed_points:\n",
    "        added = False\n",
    "        for ii in range(-same_window,same_window+1):\n",
    "            if pt+ii in points:\n",
    "                pts.add(pt)\n",
    "    \n",
    "    for pt in points:\n",
    "        add = True\n",
    "        for ii in range(-same_window,same_window+1):\n",
    "            if pt+ii in pts:\n",
    "                add = False\n",
    "        print pt,add\n",
    "        if add:\n",
    "            pts.add(pt)\n",
    "    print sorted(pts)\n",
    "    \n",
    "    smoothed_points = pts\n",
    "\n",
    "velocity_times = sorted(switch_points |smoothed_points)\n",
    "\n",
    "plt.plot(velocities)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(track[:,2])\n",
    "plt.plot(np.array(velocity_times),track[np.array(velocity_times,dtype='int'),2],'rx')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def button_change_times(button_masks):\n",
    "    last_mask = 0\n",
    "    mask_times = []\n",
    "    for t, b in enumerate(button_masks):\n",
    "        if b != last_mask:\n",
    "            mask_times.append(t)\n",
    "            last_mask = b\n",
    "    return mask_times\n",
    "\n",
    "button_times = button_change_times(track[:,3])\n",
    "\n",
    "plt.plot(track[:,2])\n",
    "plt.plot(np.array(button_times),track[np.array(button_times,dtype='int'),2],'rx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Templates is an array of model-generating functions of increasing complexity.\n",
    "templates = [\n",
    "    # Constant 0 velocity\n",
    "    (\"c0\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n, \n",
    "        mu=0,\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "    # Constant velocity from old value\n",
    "    (\"cP\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n,\n",
    "        mu=pv,\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "    # Fixed constant velocity\n",
    "    (\"cN\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n,\n",
    "        mu=pm.Normal(n+\"_N\",mu=0,sd=10),\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "    # Constant acceleration from 0\n",
    "    (\"acc0\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n,\n",
    "        mu=pm.Normal(n+\"_acc\",mu=0,sd=10)*vs[:,0],\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "    # Constant acceleration from old velocity value\n",
    "    (\"accP\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n,\n",
    "        mu=pv+pm.Normal(n+\"_acc\",mu=0,sd=10)*vs[:,0],\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "    # Constant acceleration from fixed constant velocity\n",
    "    (\"accN\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n,\n",
    "        mu=pm.Normal(n+\"_N\",mu=0,sd=10)+pm.Normal(n+\"_acc\",mu=0,sd=20)*vs[:,0],\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "]\n",
    "templates = templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_template_generate(template_i, axis, segment, prev_val):\n",
    "    axisNames = [None,\"x\",\"y\"]\n",
    "    template = templates[template_i]\n",
    "    (tn, t) = template\n",
    "    with pm.Model() as model:\n",
    "        lik = t(axisNames[axis],axis,segment,prev_val)\n",
    "        step = pm.Metropolis()\n",
    "        trace = pm.sample(5000, step, progressbar=True)\n",
    "        subtrace = trace[len(trace)/2:-1:10]\n",
    "    return (tn,model,subtrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_set_generate(data):\n",
    "    track,all_times,axis,i,j = data\n",
    "    t0 = all_times[i]\n",
    "    t1 = all_times[j]\n",
    "    print \"go\",i,j,t0,t1\n",
    "    if t0 == 0:\n",
    "        segment = track[t0+1:t1+1]-track[t0:t1]\n",
    "        prev_vel = 0\n",
    "    elif t1+1 > np.shape(track)[1]:\n",
    "        extended_track = np.concatenate((track,[track[-1]]))\n",
    "        segment = extended_track[t0+1:t1+1]-extended_track[t0:t1]\n",
    "        prev_vel = track[t0,axis]-track[t0-1,axis]\n",
    "    else:\n",
    "        #9,10,11 - 8,9,10\n",
    "        segment = track[t0+1:t1+1]-track[t0:t1]\n",
    "        prev_vel = track[t0,axis]-track[t0-1,axis]\n",
    "    segment[:,0] = range(0,np.shape(segment)[0])\n",
    "    result = map(\n",
    "        lambda ti: model_template_generate(ti, \n",
    "                                           axis,\n",
    "                                           segment,\n",
    "                                           prev_vel),\n",
    "        range(0,len(templates)))\n",
    "    return (i,j,t0,t1,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_times = sorted(set(velocity_times + button_times))\n",
    "\n",
    "all_times = all_times[:20]#[:len(all_times)/4]\n",
    "likes = [None]*len(all_times)\n",
    "\n",
    "plt.plot(velocities[:all_times[-1]])\n",
    "plt.plot(np.array(all_times),velocities[np.array(all_times,dtype='int')],'rx')\n",
    "plt.show()\n",
    "\n",
    "# Takahashi Meijin constant, 60 frames / 16 inputs ~= 4 frames per input.\n",
    "# But note that in general transitions may happen more frequently due to collisions, etc.\n",
    "min_interval = 4 \n",
    "\n",
    "for i in range(0,len(all_times)):\n",
    "    likes[i] = [None]*len(all_times)\n",
    "    t0 = all_times[i]\n",
    "    print t0\n",
    "    min_likelihood = float('inf')\n",
    "    for j in [j for j in range(i+1, len(all_times)) if all_times[j]-all_times[i] > min_interval]:\n",
    "        js = model_set_generate((track,all_times,axis,i,j))\n",
    "        the_templates = js[-1]\n",
    "        foundOne = False\n",
    "        for tn,mod,trace in the_templates:\n",
    "            logp = -np.mean([mod.logp(pt) for pt in trace])/float(all_times[j]-all_times[i])\n",
    "            print logp\n",
    "            if logp < min_likelihood:\n",
    "                min_likelihood = logp\n",
    "                foundOne = True\n",
    "        if not foundOne:\n",
    "            break\n",
    "        likes[i][j] = js\n",
    "        \n",
    "    #js = map(model_set_generate,\n",
    "    #         map(lambda j:(track,all_times,axis,i,j), [j for j in range(i+1, len(all_times)) if all_times[j]-all_times[i] > min_interval]))\n",
    "    #likes[i][i+1:len(all_times)] = js\n",
    "\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for li in likes[0:10]:\n",
    "    for lij in li[0:10]:\n",
    "        if lij is None or lij == []: \n",
    "            continue\n",
    "        (i,j,t0,t1,models) = lij\n",
    "        print i,j,t0,t1\n",
    "        for m in models:\n",
    "            print m[0],pm.df_summary(m[-1])\n",
    "        print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is the mode as of just before each switch-point, \n",
    "# and what is the accumulated cost of the approximation up to that point?\n",
    "modes = [(0,None)]*(len(all_times))\n",
    "\n",
    "#modes is offset from likes by 1\n",
    "\n",
    "ks = {\"c0\":1, \"cP\":1, \"cN\":2, \"acc0\":2, \"accP\":2, \"accN\":3}\n",
    "\n",
    "cost = 1\n",
    "\n",
    "# Takahashi Meijin constant, 60 frames / 16 inputs ~= 4 frames per input.\n",
    "# But note that in general transitions may happen more frequently due to collisions, etc.\n",
    "min_interval = 4 \n",
    "\n",
    "for j in range(1, len(all_times)):\n",
    "    least = float(\"inf\")\n",
    "    least_template = None\n",
    "    print \"j\",j\n",
    "    for i in range(0, j):\n",
    "        data = likes[i][j]\n",
    "        if not data:\n",
    "            continue\n",
    "        dt = data[3]-data[2]\n",
    "        if dt < min_interval:\n",
    "            print data[:4]\n",
    "            continue\n",
    "        the_templates = data[-1]\n",
    "        print \"i\",i\n",
    "        for tn,mod,trace in the_templates:\n",
    "            k = ks[tn]\n",
    "            summary = pm.df_summary(trace)\n",
    "            logp = np.mean([mod.logp(pt) for pt in trace])\n",
    "            # WAIC\n",
    "            #crit = -pm.stats.waic(model=mod,trace=trace)\n",
    "            # DIC\n",
    "            #crit = pm.stats.dic(model=mod,trace=trace)\n",
    "            # BPIC\n",
    "            #crit = pm.stats.bpic(model=mod,trace=trace)\n",
    "            # AICc\n",
    "            #crit = 2*k - 2 * logp + (2*(k+1)*(k+2))/(dt-k-2)\n",
    "            # BIC\n",
    "            #crit = math.log(dt)*k - 2 * logp\n",
    "            # max-likelihood\n",
    "            # crit = -logp\n",
    "            \n",
    "            crit = math.log(dt) - logp\n",
    "            m_prev = modes[i][0]\n",
    "            # ??\n",
    "            #error = summary[\"mean\"][\"y_err\"]*dt\n",
    "            here = crit + m_prev + cost\n",
    "            print i,j,data[2],data[3],tn,logp,summary[\"mean\"][\"y_err\"],crit,here,least\n",
    "            if here < least:\n",
    "                print \"update least\",here\n",
    "                least = here\n",
    "                # prev_i,this_j,t0,t1,name,summary,criterion\n",
    "                least_template = (i,j,data[2],data[3],tn,summary,crit)\n",
    "    modes[j] = (least, least_template)\n",
    "\n",
    "map(lambda m:m[1],modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_path(modes):\n",
    "    mj = len(modes)-1\n",
    "    path = [modes[mj]]\n",
    "    while mj > 0:\n",
    "        mj = modes[mj][1][0]\n",
    "        path.append(modes[mj])\n",
    "    return list(reversed(path))[1:]\n",
    "\n",
    "get_path(modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pm.df_summary(likes[0][1][4][0][2])[\"mean\"][\"y_err\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
