{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import fceulib\n",
    "import networkx as nx\n",
    "import nxpd\n",
    "import sets\n",
    "# TODO: UnionFind, probably via import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"UnionFind.py\n",
    "\n",
    "Union-find data structure. Based on Josiah Carlson's code,\n",
    "http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/215912\n",
    "with significant additional changes by D. Eppstein.\n",
    "\"\"\"\n",
    "\n",
    "class UnionFind:\n",
    "    \"\"\"Union-find data structure.\n",
    "\n",
    "    Each unionFind instance X maintains a family of disjoint sets of\n",
    "    hashable objects, supporting the following two methods:\n",
    "\n",
    "    - X[item] returns a name for the set containing the given item.\n",
    "      Each set is named by an arbitrarily-chosen one of its members; as\n",
    "      long as the set remains unchanged it will keep the same name. If\n",
    "      the item is not yet part of a set in X, a new singleton set is\n",
    "      created for it.\n",
    "\n",
    "    - X.union(item1, item2, ...) merges the sets containing each item\n",
    "      into a single larger set.  If any item is not yet part of a set\n",
    "      in X, it is added to X as one of the members of the merged set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Create a new empty union-find structure.\"\"\"\n",
    "        self.weights = {}\n",
    "        self.parents = {}\n",
    "\n",
    "    def __getitem__(self, object):\n",
    "        \"\"\"Find and return the name of the set containing the object.\"\"\"\n",
    "\n",
    "        # check for previously unknown object\n",
    "        if object not in self.parents:\n",
    "            self.parents[object] = object\n",
    "            self.weights[object] = 1\n",
    "            return object\n",
    "\n",
    "        # find path of objects leading to the root\n",
    "        path = [object]\n",
    "        root = self.parents[object]\n",
    "        while root != path[-1]:\n",
    "            path.append(root)\n",
    "            root = self.parents[root]\n",
    "\n",
    "        # compress the path and return\n",
    "        for ancestor in path:\n",
    "            self.parents[ancestor] = root\n",
    "        return root\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate through all items ever found or unioned by this structure.\"\"\"\n",
    "        return iter(self.parents)\n",
    "\n",
    "    def union(self, *objects):\n",
    "        \"\"\"Find the sets containing the objects and merge them all.\"\"\"\n",
    "        roots = [self[x] for x in objects]\n",
    "        heaviest = max([(self.weights[r],r) for r in roots])[1]\n",
    "        for r in roots:\n",
    "            if r != heaviest:\n",
    "                self.weights[heaviest] += self.weights[r]\n",
    "                self.parents[r] = heaviest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputVec = fceulib.readInputs('movie.fm2')\n",
    "collisions = pickle.load(open('collisions.pkl'))\n",
    "\n",
    "(modes, path, merged, unions, track, all_times) = pickle.load(open(\"modes.pkl\"))\n",
    "\n",
    "plt.plot(track[:,0],track[:,1])\n",
    "plt.show()\n",
    "# TODO: define axis elsewhere?\n",
    "axis = 2\n",
    "velocities = track[1:,axis]-track[:-1,axis] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = track[0,0]\n",
    "transitions = {}\n",
    "# Edges into [outer] from [inner]\n",
    "entries_from = {m: {m: [] for m in merged} \n",
    "                for m in merged}\n",
    "# Edges into [outer]\n",
    "entries = {m: [] for m in merged}\n",
    "for t in range(1,len(path)):\n",
    "    if t == 0:\n",
    "        prev = -1\n",
    "    else:\n",
    "        prev = unions[t-1]\n",
    "    start = all_times[path[t][1][0]]\n",
    "    \n",
    "    entries_from[unions[t]][prev].append(start)\n",
    "    entries[unions[t]].append(start)\n",
    "    transitions[start] = (prev,unions[t])\n",
    "    #print (path[t][1][0],start),\":\",prev,\"->\",unions[t],\"\\n\",path[unions[t]][1][2][0],path[unions[t]][1][2][1].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = nx.MultiDiGraph()\n",
    "to_add = {}\n",
    "for tgt,srcs in entries_from.items():\n",
    "    G.add_node(tgt,label=str(tgt))\n",
    "    # Let's learn about tgt\n",
    "    mtype = path[tgt][1][2][0]\n",
    "    mparams = path[tgt][1][2][1].params\n",
    "    params = {\"type\": mtype}\n",
    "    if mtype == 'c0':\n",
    "        pass\n",
    "    elif mtype == 'cP':\n",
    "        pass\n",
    "    elif mtype == 'cN':\n",
    "        params[\"N\"] = mparams[1]\n",
    "    elif mtype == 'acc0':\n",
    "        params[\"acc\"] = mparams[1]\n",
    "    elif mtype == 'accP':\n",
    "        params[\"acc\"] = mparams[1]\n",
    "    elif mtype == 'accN':\n",
    "        params[\"N\"] = mparams[1]\n",
    "        params[\"acc\"] = mparams[2]\n",
    "    for k,v in params.items():\n",
    "        G.node[tgt][\"label\"] = (G.node[tgt][\"label\"] + \"\\n\" + \"{}: {}\".format(k,v))\n",
    "    print tgt,params\n",
    "    for src,times in srcs.items():\n",
    "        for t in times:\n",
    "            if (src,tgt) not in to_add:\n",
    "                to_add[(src,tgt)] = []\n",
    "            to_add[(src,tgt)].append('{}'.format(t))\n",
    "for e in to_add:\n",
    "    print e[0],e[1],''.join(to_add[e])\n",
    "    G.add_edge(e[0],e[1])\n",
    "\n",
    "G.add_node(-1)\n",
    "G.add_edge(-1, unions[0])\n",
    "\n",
    "m2i = {m:i for i,m in enumerate(merged)}\n",
    "plt.plot(velocities)\n",
    "plt.plot(np.array(all_times),velocities[np.array(all_times,dtype='int')],'rx')\n",
    "for u in sorted(unions):\n",
    "    t0 = all_times[path[u][1][0]]\n",
    "    t1 = all_times[path[u][1][1]]\n",
    "    u_ = m2i[unions[u]]\n",
    "    plt.plot([t0,t1],[unions[u]+10,unions[u]+10])#,colors[u])\n",
    "        \n",
    "plt.xlim((50,100))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def button_changes(button_masks):\n",
    "    last_mask = 0\n",
    "    mask_times = {}\n",
    "    for t, b in enumerate(button_masks):\n",
    "        b_ = int(b)\n",
    "        buttons = []\n",
    "        for ii,c in enumerate(list('RLDUTSBA')):\n",
    "            if b_ & (1 << (7-ii)):\n",
    "                buttons.append(c)\n",
    "        l_ = int(last_mask)\n",
    "        last_buttons = []\n",
    "        for ii,c in enumerate(list('RLDUTSBA')):\n",
    "            if l_ & (1 << (7-ii)):\n",
    "                last_buttons.append(c)\n",
    "        mask_times[t] = (tuple(last_buttons),tuple(buttons))\n",
    "        last_mask = b\n",
    "    \n",
    "    return mask_times\n",
    "\n",
    "button_change_times = button_changes(inputVec)\n",
    "for t in sorted(button_change_times):\n",
    "    pass #print t, button_change_times[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sign(num):\n",
    "    if num < 0:\n",
    "        return -1\n",
    "    if num > 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def button_diff(btnsA, btnsB):\n",
    "    return set(btnsA) - set(btnsB)\n",
    "\n",
    "def button_intersect(btnsA, btnsB):\n",
    "    return set(btnsA) & set(btnsB)\n",
    "\n",
    "def button_union(btnsA, btnsB):\n",
    "    return set(btnsA) | set(btnsB)\n",
    "\n",
    "def button_preds(button_pairs):\n",
    "    here_i = set()\n",
    "    for bp in button_pairs:\n",
    "        released_i = button_diff(bp[0], bp[1])\n",
    "        pressed_i = button_diff(bp[1], bp[0])    \n",
    "        held_i = bp[1]\n",
    "        for ri in released_i:\n",
    "            here_i.add((\"release\",ri))\n",
    "        for ri in pressed_i:\n",
    "            here_i.add((\"press\",ri))\n",
    "        for ri in held_i:\n",
    "            here_i.add((\"hold\",ri))\n",
    "    return list(here_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_preds = [set()]*len(velocities)\n",
    "for t in range(0,len(velocities)):\n",
    "    # TODO: button lag variables\n",
    "    psi = ([button_change_times[start_time+t+i]\n",
    "            for i in range(0, 1)],\n",
    "            #  TODO: stopped colliding/started colliding?  That would mean\n",
    "           #   I could say \"started colliding with X on bottom and also zin,-1\"\n",
    "           #   to help find solid things.\n",
    "           #     ... no... acc,0 should be enough (walking right across solid tiles)\n",
    "           #     but I should also consider \n",
    "           #     a more sophisticated notion of collision.\n",
    "           #      e.g. \"bottom\" is good but it should be the lowest bottom tile.\n",
    "           #      how can I get that?  can I get that?\n",
    "           #      (OTOH, maybe this isn't even necessary if e.g. \"touching my feet against sky\"\n",
    "          #        doesn't cause vy=0 as often as \"touching my feet against ground\" does. so let's be\n",
    "          #         sure that's surfaced!)\n",
    "           # TODO: collision lag variables?\n",
    "            collisions.get(start_time+t+(0),set()),\n",
    "            (velocities[t-1],velocities[t-0])\n",
    "          )\n",
    "    buttons_i = psi[0]\n",
    "    here_i = button_preds(buttons_i)\n",
    "    for coli in psi[1]:\n",
    "        here_i.append((\"col\",coli))\n",
    "    vel0,vel1 = psi[2]\n",
    "    if vel0 < vel1:\n",
    "        here_i.append((\"acc\",1))\n",
    "    if vel0 > vel1:\n",
    "        here_i.append((\"acc\",-1))\n",
    "    if vel0 == vel1:\n",
    "        here_i.append((\"acc\",0))\n",
    "    if vel1 < 0:\n",
    "        here_i.append((\"vel\",-1))\n",
    "    if vel1 > 0:\n",
    "        here_i.append((\"vel\",1))\n",
    "    if vel1 == 0:\n",
    "        here_i.append((\"vel\",0))\n",
    "    if vel0 < 0 and vel1 > 0:\n",
    "        here_i.append((\"zc\",1))\n",
    "    if vel0 > 0 and vel1 < 0:\n",
    "        here_i.append((\"zc\",-1))\n",
    "    if vel0 < 0 and vel1 == 0:\n",
    "        here_i.append((\"zin\",1))\n",
    "    if vel0 > 0 and vel1 == 0:\n",
    "        here_i.append((\"zin\",-1))\n",
    "    if vel0 == 0 and vel1 < 0:\n",
    "        here_i.append((\"zout\",-1))\n",
    "    if vel0 == 0 and vel1 > 0:\n",
    "        here_i.append((\"zout\",1))\n",
    "    #cur_mode = X\n",
    "    # TODO: touched global min/max of velocity for current mode\n",
    "    #mode_max = max(velocities_in_cur_mode)\n",
    "    #mode_min = min(velocities_in_cur_mode)\n",
    "    #if vel1 == mode_max and vel0 != mode_max:\n",
    "    #  touched max\n",
    "    #if vel1 == mode_min and vel0 != mode_min:\n",
    "    #  touched min\n",
    "    #if vel1 == mode_max:\n",
    "    #  in min\n",
    "    #if vel1 == mode_min:\n",
    "    #  in max\n",
    "    base_preds[t] = set(here_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intervals_any_contains(intervals, t):\n",
    "    if intervals is None:\n",
    "        return True\n",
    "    for (s,e) in intervals:\n",
    "        if s <= t <= e:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def intervals_summed_length(intervals):\n",
    "    return sum([e-s for (s,e) in intervals])\n",
    "\n",
    "def count_events(preds,intervals):\n",
    "    all_counts = {}\n",
    "    counts_by_time = {}\n",
    "    for t,ps in enumerate(preds):\n",
    "        if not intervals_any_contains(intervals, t): continue\n",
    "        counts_by_time[t] = {}\n",
    "        for p in ps:\n",
    "            all_counts[p] = all_counts.get(p,0)+1\n",
    "            counts_by_time[t][p] = counts_by_time[t].get(p,0)+1\n",
    "        if t in transitions:\n",
    "            tr = transitions[t]\n",
    "            key = (\"tr\",tr)\n",
    "            all_counts[key] = all_counts.get(key,0)+1\n",
    "            counts_by_time[t][key] = counts_by_time[t].get(key,0)+1\n",
    "            (_,dest) = tr\n",
    "            keystar = (\"tr\",(\"*\",dest))\n",
    "            all_counts[keystar] = all_counts.get(keystar,0)+1\n",
    "            counts_by_time[t][keystar] = counts_by_time[t].get(keystar,0)+1\n",
    "    return all_counts, counts_by_time\n",
    "\n",
    "def count_coevents(preds,intervals):\n",
    "    all_counts = {}\n",
    "    counts_by_time = {}\n",
    "    for t,ps in enumerate(preds):\n",
    "        if not intervals_any_contains(intervals, t): continue\n",
    "        counts_by_time[t] = {}\n",
    "        for p1 in ps:\n",
    "            for p2 in ps:\n",
    "                p = (p1,p2)\n",
    "                all_counts[p] = all_counts.get(p,0)+1\n",
    "                counts_by_time[t][p] = counts_by_time[t].get(p,0)+1\n",
    "        if t in transitions:\n",
    "            for p1 in ps:\n",
    "                tr = transitions[t]\n",
    "                key = ((\"tr\",tr),p1)\n",
    "                all_counts[key] = all_counts.get(key,0)+1\n",
    "                counts_by_time[t][key] = counts_by_time[t].get(key,0)+1\n",
    "                (_,dest) = tr\n",
    "                keystar = ((\"tr\",(\"*\",dest)),p1)\n",
    "                all_counts[keystar] = all_counts.get(keystar,0)+1\n",
    "                counts_by_time[t][keystar] = counts_by_time[t].get(keystar,0)+1\n",
    "    return all_counts, counts_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_counts, counts_by_time = count_events(base_preds,None)\n",
    "all_cocounts, cocounts_by_time = count_coevents(base_preds,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's figure out which tiles block movement on which sides!\n",
    "# co-occurrence of (col, BLAH) and acc0 for each BLAH.\n",
    "# cluster together tiles which block on a given side (for now, all those with co-occurrence over threshold)\n",
    "# then add new preds!\n",
    "\n",
    "def cond_prob(e1s, e2, all_counts, counts_by_time):\n",
    "    p2 = all_counts[e2]/float(len(counts_by_time))\n",
    "    count12 = 0\n",
    "    for t,cs in counts_by_time.items():\n",
    "        any_e1_present = False\n",
    "        for e1 in e1s:\n",
    "            if e1 in cs:\n",
    "                any_e1_present = True\n",
    "                break\n",
    "        if any_e1_present and (e2 in cs):\n",
    "            count12 += 1\n",
    "    p12 = count12 / float(len(counts_by_time))\n",
    "    return p12 / p2\n",
    "\n",
    "block_chance = {}\n",
    "for thing,count in all_counts.items():\n",
    "    # TODO: generalize back to all sides, but note \"colliding on right with something\" -> \"vely=0\" is not that sensible.\n",
    "    #  need a notion of acc,vel,zin,zout and _other axis_ acc,vel,zin,zout.\n",
    "    if thing[0] != \"col\": \n",
    "        continue\n",
    "    block_chance[thing] = cond_prob([(\"vel\",0),(\"acc\",0)], \n",
    "                                    thing,\n",
    "                                    all_counts,\n",
    "                                    counts_by_time)\n",
    "\n",
    "merged_by_side = {}\n",
    "# TODO: generalize back to all sides\n",
    "for side in [\"bottom\",\"right\",\"left\",\"top\"]:\n",
    "    # Let's pretend colliding with sprites is the same as colliding with tiles?  Maybe needed for moving platforms?\n",
    "    blockings = filter(lambda (col,prob):(col[1][0][0] != \"solid\" and \n",
    "                                          col[1][1] == side and \n",
    "                                          prob > 0.8),\n",
    "                       block_chance.items())\n",
    "    merged_by_side[side] = set()\n",
    "    for bcol,bprob in blockings:\n",
    "        merged_by_side[side].add(bcol)\n",
    "    merged_by_side[side] = sets.ImmutableSet(merged_by_side[side])\n",
    "        \n",
    "    \n",
    "#color_tiles = pickle.load(open('tile2colorized.pkl'))\n",
    "for side,bcols in merged_by_side.items():\n",
    "    print \"----\\n{}\\n----\".format(side)\n",
    "    for bc in bcols:\n",
    "        print block_chance[bc],bc[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's add new preds now!\n",
    "extended_preds = [set() for i in range(0,len(base_preds))]\n",
    "for t,pset in enumerate(base_preds):\n",
    "    for side,equiv in merged_by_side.items():\n",
    "        found = False\n",
    "        for pred in pset:\n",
    "            extended_preds[t].add(pred)\n",
    "            if not found and pred[0] == \"col\" and pred in equiv:\n",
    "                extended_preds[t].add((\"col\", ((\"solid\", equiv), side)))\n",
    "                found = True\n",
    "all_counts,counts_by_time = count_events(extended_preds,None)\n",
    "all_cocounts,cocounts_by_time = count_coevents(extended_preds,None)\n",
    "\n",
    "all_counts,counts_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: update to support intervals?\n",
    "\n",
    "def count_conditional_events(preds,condition):\n",
    "    all_counts = {}\n",
    "    counts_by_time = {}\n",
    "    for t,ps in enumerate(preds):\n",
    "        counts_by_time[t] = {}\n",
    "        if condition in ps:\n",
    "            for p in ps:\n",
    "                all_counts[p] = all_counts.get(p,0)+1\n",
    "                counts_by_time[t][p] = counts_by_time[t].get(p,0)+1\n",
    "            if t in transitions:\n",
    "                tr = transitions[t]\n",
    "                key = (\"tr\",tr)\n",
    "                all_counts[key] = all_counts.get(key,0)+1\n",
    "                counts_by_time[t][key] = counts_by_time[t].get(key,0)+1\n",
    "                (_,dest) = tr\n",
    "                keystar = (\"tr\",(\"*\",dest))\n",
    "                all_counts[keystar] = all_counts.get(keystar,0)+1\n",
    "                counts_by_time[t][keystar] = counts_by_time[t].get(keystar,0)+1\n",
    "    return all_counts\n",
    "\n",
    "def count_joint_events(preds,conditions):\n",
    "    count = 0\n",
    "    for t,ps in enumerate(preds):\n",
    "        trans = transitions.get(t,-1)\n",
    "        is_good = True\n",
    "        for condition in conditions:\n",
    "            if condition not in ps and condition != trans:\n",
    "                is_good = False\n",
    "                break\n",
    "        if is_good:\n",
    "            count += 1\n",
    "    return count\n",
    "    \n",
    "def count_conditional_coevents(preds,condition):\n",
    "    all_counts = {}\n",
    "    counts_by_time = {}\n",
    "    for t,ps in enumerate(preds):\n",
    "        counts_by_time[t] = {}\n",
    "        if condition in ps:\n",
    "            for p1 in ps:\n",
    "                for p2 in ps:\n",
    "                    p = (p1,p2)\n",
    "                    all_counts[p] = all_counts.get(p,0)+1\n",
    "                    counts_by_time[t][p] = counts_by_time[t].get(p,0)+1\n",
    "            if t in transitions:\n",
    "                for p1 in ps:\n",
    "                    tr = transitions[t]\n",
    "                    key = ((\"tr\",tr),p1)\n",
    "                    all_counts[key] = all_counts.get(key,0)+1\n",
    "                    counts_by_time[t][key] = counts_by_time[t].get(key,0)+1\n",
    "                    (_,dest) = tr\n",
    "                    keystar = ((\"tr\",(\"*\",dest)),p1)\n",
    "                    all_counts[keystar] = all_counts.get(keystar,0)+1\n",
    "                    counts_by_time[t][keystar] = counts_by_time[t].get(keystar,0)+1\n",
    "    return all_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mode_periods = {}\n",
    "\n",
    "for t in range(0,len(path)):\n",
    "    cur = unions[t]\n",
    "    start = all_times[path[t][1][0]]\n",
    "    if t + 1 < len(path):\n",
    "        end = all_times[path[t+1][1][0]]\n",
    "    else:\n",
    "        end = len(velocities)\n",
    "    if cur not in mode_periods:\n",
    "        mode_periods[cur] = []\n",
    "    mode_periods[cur].append((start,end))\n",
    "\n",
    "transition_leadin_intervals = {}\n",
    "\n",
    "for src in merged:\n",
    "    for tgt in merged:\n",
    "        if src == tgt: continue\n",
    "        intervals = [(s,e)\n",
    "                      for (s,e) in mode_periods[src] \n",
    "                      if e in transitions and transitions[e][1] == tgt]\n",
    "        transition_leadin_intervals[(src,tgt)] = intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### tile2colorized = pickle.load(open('tile2colorized.pkl'))\n",
    "id2colorized = pickle.load(open('id2sprites.pkl'))[1]\n",
    "\n",
    "inv_len = 1.0/float(len(track))\n",
    "npmis = {}\n",
    "pmis = {}\n",
    "\n",
    "for m1 in merged:\n",
    "    for m2 in merged:\n",
    "        if m1 == m2: continue\n",
    "        transition = (m1,m2)\n",
    "        intervals = transition_leadin_intervals[transition]\n",
    "        intvl_len = intervals_summed_length(intervals)\n",
    "        if intvl_len == 0: continue\n",
    "        tr_counts,_by_time = count_events(extended_preds, intervals)\n",
    "        tr_cocounts,_by_time = count_coevents(extended_preds, intervals)\n",
    "        tr_inv_len = 1.0/float(intvl_len)\n",
    "        for pred in tr_counts:\n",
    "            if pred != transition:\n",
    "                p1 = tr_counts[pred]*tr_inv_len\n",
    "                p2 = tr_counts[(\"tr\",transition)]*tr_inv_len\n",
    "                cooccur = ((\"tr\",transition),pred)\n",
    "                if cooccur in tr_cocounts:\n",
    "                    p12 = tr_cocounts[cooccur]*tr_inv_len\n",
    "                else:\n",
    "                    p12 = 0.0\n",
    "                if p12/(p1*p2) != 0.0:\n",
    "                    if transition not in npmis:\n",
    "                        npmis[transition] = {}\n",
    "                    pmi = np.log(p12/(p1*p2))\n",
    "                    npmi = pmi/-np.log(p12)\n",
    "                    pmis[(transition,pred)] = pmi\n",
    "                    npmis[transition][pred] = npmi\n",
    "                else:\n",
    "                    npmis[transition][pred] = -1.0\n",
    "\n",
    "for t in sorted(npmis):\n",
    "    for e1,pmi in reversed(sorted(npmis[t].items(), lambda a,b:sign(b[1] - a[1]))):\n",
    "        if pmi > 0.4:\n",
    "#             conditioned_px = count_conditional_events(preds,e1)\n",
    "#             conditioned_pxy = count_conditional_coevents(preds,e1)\n",
    "            print t, e1, pmi\n",
    "#             if False:\n",
    "#                 for pmi2 in reversed(sorted(npmis[t])):\n",
    "#                     if pmi != pmi2:\n",
    "#                         e2 =  npmis[t][pmi2]\n",
    "#                         pmi_t_e1 = pmis[(t,e1)]\n",
    "\n",
    "\n",
    "#                         p_t_e2_I_e1 = conditioned_pxy.get(((\"tr\",t),e2),0)/float(all_counts[e1])\n",
    "#                         p_t_I_e1 = conditioned_px.get((\"tr\",t),0)/float(all_counts[e1])\n",
    "#                         p_e2_I_e1 = conditioned_px.get(e2,0)/float(all_counts[e1])\n",
    "#                         if p_t_I_e1 == 0.0 or p_e2_I_e1 == 0.0:\n",
    "#                             p_t_e2_I_e1 = 0.0\n",
    "#                             p_t_I_e1 = 1\n",
    "#                             p_e2_I_e1 = 1\n",
    "\n",
    "#                         pmi_t_e1_e2 = (pmi_t_e1 + np.log(p_t_e2_I_e1/(p_t_I_e1*p_e2_I_e1)))\n",
    "\n",
    "#                         p_t_e1_e2 = count_joint_events(preds,[e1,e2,t])*inv_len\n",
    "#                         if p_t_e1_e2 == 0.0:\n",
    "#                             npmi_t_e1_e2 = -1.0\n",
    "#                         else:\n",
    "#                             npmi_t_e1_e2 = pmi_t_e1_e2/-np.log(p_t_e1_e2)\n",
    "#                         if npmi_t_e1_e2 > 0.0:\n",
    "#                             print 'pmi({};{},{})'.format(t,e1,e2), npmi_t_e1_e2, pmi,pmi2\n",
    "#                             if 'col' in e2 and 'tile' in e2[1][0]:\n",
    "#                                 plt.imshow(tile2colorized[e2[1][0][:2]]/255.)\n",
    "#                                 plt.show()\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Joe's output version\n",
    "\n",
    "relevance_threshold = 0.6\n",
    "universality_threshold = 0.9\n",
    "negation_threshold = -1.0\n",
    "\n",
    "# TODO: more selective prioritizing of buttons (press/release over hold) vs \n",
    "# collisions vs qualitative stuff.\n",
    "\n",
    "for tr,pred_npmis in npmis.items():# + paired_npmis.items():\n",
    "    cond_probs = {k: cond_prob([k], (\"tr\",tr), all_counts, counts_by_time) \n",
    "                  for k in pred_npmis.keys()}\n",
    "    relevants = {k: npmi for (k,npmi) in pred_npmis.items() if npmi >= relevance_threshold}\n",
    "    negations = {k: npmi for (k,npmi) in pred_npmis.items() if npmi <= negation_threshold}\n",
    "    conjuncts = set(filter(lambda k:cond_probs[k] >= universality_threshold, relevants.keys()))\n",
    "    disjuncts = set(filter(lambda k:cond_probs[k] < universality_threshold and k not in conjuncts, relevants.keys()))\n",
    "    print \"-------\\nTransition:\",tr\n",
    "    print \"-----\\nCond Probs:\"\n",
    "    print \"\\n\".join(map(str,sorted(cond_probs.items(), lambda a,b:sign(b[1]-a[1]))))\n",
    "    print \"-----\\nNPMIs:\"\n",
    "    print \"\\n\".join(map(str,sorted(pred_npmis.items(), lambda a,b:sign(b[1]-a[1]))))\n",
    "    print \"-----\\nRelevant:\\n\",\"\\n\".join(map(str,relevants.items()))\n",
    "    print \"-----\\nConjuncts:\\n\",\" & \".join(map(str,conjuncts))\n",
    "    print \"-----\\nDisjuncts:\\n\",\" | \".join(map(str,disjuncts))\n",
    "    print \"-----\\nNegations:\\n\",\" & \".join(map(lambda k:\"~\" + str(k),negations))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adam's output version\n",
    "\n",
    "import operator\n",
    "relevance_threshold = 0.4\n",
    "universality_threshold = 0.8\n",
    "negation_threshold = -1.0\n",
    "for tr in sorted(npmis):# + paired_npmis.items():\n",
    "    if hasattr(tr, \"__len__\"):\n",
    "        if tr[0] != tr[1]:\n",
    "            pred_npmis = npmis[tr]\n",
    "            universals = {k: npmi for (k,npmi) in pred_npmis.items() if npmi >= universality_threshold}\n",
    "            relevants = {k: npmi for (k,npmi) in pred_npmis.items() if npmi >= relevance_threshold and k not in universals}\n",
    "            negations = {k: npmi for (k,npmi) in pred_npmis.items() if npmi <= negation_threshold}\n",
    "            print \"\\n\"\n",
    "            print \"-------\\nTransition:\",tr\n",
    "            print \"-----\\nUniversals:\\n\",\"\\n\".join(map(str,map(lambda a: a[0],sorted(universals.items(), key=operator.itemgetter(1)))))\n",
    "            print \"-----\\nRelevant:\\n\",\"\\n\".join(map(str,map(lambda a: a[0],sorted(relevants.items(), key=operator.itemgetter(1)))))\n",
    "            #print \"-----\\nNegations:\\n\",\" & \".join(map(lambda k:\"~\" + str(k),negations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump((npmis, paired_npmis, entries, entries_from, new_preds, modes, merged, unions, track, inputVec, all_times), \n",
    "            open(\"edges.pkl\",'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
