{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import fceulib\n",
    "import networkx as nx\n",
    "import nxpd\n",
    "import sets\n",
    "# TODO: UnionFind, probably via import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"UnionFind.py\n",
    "\n",
    "Union-find data structure. Based on Josiah Carlson's code,\n",
    "http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/215912\n",
    "with significant additional changes by D. Eppstein.\n",
    "\"\"\"\n",
    "\n",
    "class UnionFind:\n",
    "    \"\"\"Union-find data structure.\n",
    "\n",
    "    Each unionFind instance X maintains a family of disjoint sets of\n",
    "    hashable objects, supporting the following two methods:\n",
    "\n",
    "    - X[item] returns a name for the set containing the given item.\n",
    "      Each set is named by an arbitrarily-chosen one of its members; as\n",
    "      long as the set remains unchanged it will keep the same name. If\n",
    "      the item is not yet part of a set in X, a new singleton set is\n",
    "      created for it.\n",
    "\n",
    "    - X.union(item1, item2, ...) merges the sets containing each item\n",
    "      into a single larger set.  If any item is not yet part of a set\n",
    "      in X, it is added to X as one of the members of the merged set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Create a new empty union-find structure.\"\"\"\n",
    "        self.weights = {}\n",
    "        self.parents = {}\n",
    "\n",
    "    def __getitem__(self, object):\n",
    "        \"\"\"Find and return the name of the set containing the object.\"\"\"\n",
    "\n",
    "        # check for previously unknown object\n",
    "        if object not in self.parents:\n",
    "            self.parents[object] = object\n",
    "            self.weights[object] = 1\n",
    "            return object\n",
    "\n",
    "        # find path of objects leading to the root\n",
    "        path = [object]\n",
    "        root = self.parents[object]\n",
    "        while root != path[-1]:\n",
    "            path.append(root)\n",
    "            root = self.parents[root]\n",
    "\n",
    "        # compress the path and return\n",
    "        for ancestor in path:\n",
    "            self.parents[ancestor] = root\n",
    "        return root\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate through all items ever found or unioned by this structure.\"\"\"\n",
    "        return iter(self.parents)\n",
    "\n",
    "    def union(self, *objects):\n",
    "        \"\"\"Find the sets containing the objects and merge them all.\"\"\"\n",
    "        roots = [self[x] for x in objects]\n",
    "        heaviest = max([(self.weights[r],r) for r in roots])[1]\n",
    "        for r in roots:\n",
    "            if r != heaviest:\n",
    "                self.weights[heaviest] += self.weights[r]\n",
    "                self.parents[r] = heaviest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputVec = fceulib.readInputs('movie.fm2')\n",
    "collisions = pickle.load(open('collisions.pkl'))\n",
    "\n",
    "(modes, path, merged, unions, track, all_times) = pickle.load(open(\"modes.pkl\"))\n",
    "\n",
    "plt.plot(track[:,0],track[:,1])\n",
    "plt.show()\n",
    "# TODO: define axis elsewhere?\n",
    "axis = 2\n",
    "velocities = track[1:,axis]-track[:-1,axis] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = track[0,0]\n",
    "transitions = {}\n",
    "# Edges into [outer] from [inner]\n",
    "entries_from = {m: {m: [] for m in merged} \n",
    "                for m in merged}\n",
    "# Edges into [outer]\n",
    "entries = {m: [] for m in merged}\n",
    "for t in range(1,len(path)):\n",
    "    if t == 0:\n",
    "        prev = -1\n",
    "    else:\n",
    "        prev = unions[t-1]\n",
    "    start = all_times[path[t][1][0]]\n",
    "    \n",
    "    entries_from[unions[t]][prev].append(start)\n",
    "    entries[unions[t]].append(start)\n",
    "    transitions[start] = (prev,unions[t])\n",
    "    #print (path[t][1][0],start),\":\",prev,\"->\",unions[t],\"\\n\",path[unions[t]][1][2][0],path[unions[t]][1][2][1].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = nx.MultiDiGraph()\n",
    "to_add = {}\n",
    "for tgt,srcs in entries_from.items():\n",
    "    G.add_node(tgt,label=str(tgt))\n",
    "    # Let's learn about tgt\n",
    "    mtype = path[tgt][1][2][0]\n",
    "    mparams = path[tgt][1][2][1].params\n",
    "    params = {\"type\": mtype}\n",
    "    if mtype == 'c0':\n",
    "        pass\n",
    "    elif mtype == 'cP':\n",
    "        pass\n",
    "    elif mtype == 'cN':\n",
    "        params[\"N\"] = mparams[1]\n",
    "    elif mtype == 'acc0':\n",
    "        params[\"acc\"] = mparams[1]\n",
    "    elif mtype == 'accP':\n",
    "        params[\"acc\"] = mparams[1]\n",
    "    elif mtype == 'accN':\n",
    "        params[\"N\"] = mparams[1]\n",
    "        params[\"acc\"] = mparams[2]\n",
    "    for k,v in params.items():\n",
    "        G.node[tgt][\"label\"] = (G.node[tgt][\"label\"] + \"\\n\" + \"{}: {}\".format(k,v))\n",
    "    print tgt,params\n",
    "    for src,times in srcs.items():\n",
    "        for t in times:\n",
    "            if (src,tgt) not in to_add:\n",
    "                to_add[(src,tgt)] = []\n",
    "            to_add[(src,tgt)].append('{}'.format(t))\n",
    "for e in to_add:\n",
    "    print e[0],e[1],''.join(to_add[e])\n",
    "    G.add_edge(e[0],e[1])\n",
    "\n",
    "G.add_node(-1)\n",
    "G.add_edge(-1, unions[0])\n",
    "\n",
    "m2i = {m:i for i,m in enumerate(merged)}\n",
    "plt.plot(velocities)\n",
    "plt.plot(np.array(all_times),velocities[np.array(all_times,dtype='int')],'rx')\n",
    "for u in sorted(unions):\n",
    "    t0 = all_times[path[u][1][0]]\n",
    "    t1 = all_times[path[u][1][1]]\n",
    "    u_ = m2i[unions[u]]\n",
    "    plt.plot([t0,t1],[unions[u]+10,unions[u]+10])#,colors[u])\n",
    "        \n",
    "plt.xlim((50,100))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def button_changes(button_masks):\n",
    "    last_mask = 0\n",
    "    mask_times = {}\n",
    "    for t, b in enumerate(button_masks):\n",
    "        b_ = int(b)\n",
    "        buttons = []\n",
    "        for ii,c in enumerate(list('RLDUTSBA')):\n",
    "            if b_ & (1 << (7-ii)):\n",
    "                buttons.append(c)\n",
    "        l_ = int(last_mask)\n",
    "        last_buttons = []\n",
    "        for ii,c in enumerate(list('RLDUTSBA')):\n",
    "            if l_ & (1 << (7-ii)):\n",
    "                last_buttons.append(c)\n",
    "        mask_times[t] = (tuple(last_buttons),tuple(buttons))\n",
    "        last_mask = b\n",
    "    \n",
    "    return mask_times\n",
    "\n",
    "button_change_times = button_changes(inputVec)\n",
    "for t in sorted(button_change_times):\n",
    "    pass #print t, button_change_times[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sign(num):\n",
    "    if num < 0:\n",
    "        return -1\n",
    "    if num > 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def button_diff(btnsA, btnsB):\n",
    "    return set(btnsA) - set(btnsB)\n",
    "\n",
    "def button_intersect(btnsA, btnsB):\n",
    "    return set(btnsA) & set(btnsB)\n",
    "\n",
    "def button_union(btnsA, btnsB):\n",
    "    return set(btnsA) | set(btnsB)\n",
    "\n",
    "def button_preds(button_pairs):\n",
    "    here_i = set()\n",
    "    for bp in button_pairs:\n",
    "        released_i = button_diff(bp[0], bp[1])\n",
    "        pressed_i = button_diff(bp[1], bp[0])    \n",
    "        held_i = bp[1]\n",
    "        for ri in released_i:\n",
    "            here_i.add((\"release\",ri))\n",
    "        for ri in pressed_i:\n",
    "            here_i.add((\"press\",ri))\n",
    "        for ri in held_i:\n",
    "            here_i.add((\"hold\",ri))\n",
    "    return list(here_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = [set()]*len(velocities)\n",
    "for t in range(0,len(velocities)):\n",
    "    psi = ([button_change_times[start_time+t+i]\n",
    "            for i in range(0, 1)],\n",
    "            #  TODO: stopped colliding/started colliding?  That would mean\n",
    "           #   I could say \"started colliding with X on bottom and also zin,-1\"\n",
    "           #   to help find solid things.\n",
    "           #     ... no... acc,0 should be enough (walking right across solid tiles)\n",
    "           #     but I should also consider \n",
    "           #     a more sophisticated notion of collision.\n",
    "           #      e.g. \"bottom\" is good but it should be the lowest bottom tile.\n",
    "           #      how can I get that?  can I get that?\n",
    "           #      (OTOH, maybe this isn't even necessary if e.g. \"touching my feet against sky\"\n",
    "          #        doesn't cause vy=0 as often as \"touching my feet against ground\" does. so let's be\n",
    "          #         sure that's surfaced!)\n",
    "            collisions.get(start_time+t+(0),set()),\n",
    "            (velocities[t-1],velocities[t-0])\n",
    "          )\n",
    "    buttons_i = psi[0]\n",
    "    here_i = button_preds(buttons_i)\n",
    "    for coli in psi[1]:\n",
    "        here_i.append((\"col\",coli))\n",
    "    vel0,vel1 = psi[2]\n",
    "    if vel0 < vel1:\n",
    "        here_i.append((\"acc\",1))\n",
    "    if vel0 > vel1:\n",
    "        here_i.append((\"acc\",-1))\n",
    "    if vel0 == vel1:\n",
    "        here_i.append((\"acc\",0))\n",
    "    if vel1 < 0:\n",
    "        here_i.append((\"vel\",-1))\n",
    "    if vel1 > 0:\n",
    "        here_i.append((\"vel\",1))\n",
    "    if vel1 == 0:\n",
    "        here_i.append((\"vel\",0))\n",
    "    if vel0 < 0 and vel1 > 0:\n",
    "        here_i.append((\"zc\",1))\n",
    "    if vel0 > 0 and vel1 < 0:\n",
    "        here_i.append((\"zc\",-1))\n",
    "    if vel0 < 0 and vel1 == 0:\n",
    "        here_i.append((\"zin\",1))\n",
    "    if vel0 > 0 and vel1 == 0:\n",
    "        here_i.append((\"zin\",-1))\n",
    "    if vel0 == 0 and vel1 < 0:\n",
    "        here_i.append((\"zout\",-1))\n",
    "    if vel0 == 0 and vel1 > 0:\n",
    "        here_i.append((\"zout\",1))\n",
    "    #cur_mode = X\n",
    "    # TODO: touched global min/max of velocity for current mode\n",
    "    #mode_max = max(velocities_in_cur_mode)\n",
    "    #mode_min = min(velocities_in_cur_mode)\n",
    "    #if vel1 == mode_max and vel0 != mode_max:\n",
    "    #  touched max\n",
    "    #if vel1 == mode_min and vel0 != mode_min:\n",
    "    #  touched min\n",
    "    #if vel1 == mode_max:\n",
    "    #  in min\n",
    "    #if vel1 == mode_min:\n",
    "    #  in max\n",
    "    preds[t] = set(here_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_events(preds):\n",
    "    all_counts = {}\n",
    "    counts_by_time = {}\n",
    "    for t,ps in enumerate(preds):\n",
    "        counts_by_time[t] = {}\n",
    "        for p in ps:\n",
    "            all_counts[p] = all_counts.get(p,0)+1\n",
    "            counts_by_time[t][p] = counts_by_time[t].get(p,0)+1\n",
    "        if t in transitions:\n",
    "            tr = transitions[t]\n",
    "            key = (\"tr\",tr)\n",
    "            all_counts[key] = all_counts.get(key,0)+1\n",
    "            counts_by_time[t][key] = counts_by_time[t].get(key,0)+1\n",
    "            (_,dest) = tr\n",
    "            keystar = (\"tr\",(\"*\",dest))\n",
    "            all_counts[keystar] = all_counts.get(keystar,0)+1\n",
    "            counts_by_time[t][keystar] = counts_by_time[t].get(keystar,0)+1\n",
    "    return all_counts, counts_by_time\n",
    "\n",
    "def count_coevents(preds):\n",
    "    all_counts = {}\n",
    "    counts_by_time = {}\n",
    "    for t,ps in enumerate(preds):\n",
    "        counts_by_time[t] = {}\n",
    "        for p1 in ps:\n",
    "            for p2 in ps:\n",
    "                p = (p1,p2)\n",
    "                all_counts[p] = all_counts.get(p,0)+1\n",
    "                counts_by_time[t][p] = counts_by_time[t].get(p,0)+1\n",
    "        if t in transitions:\n",
    "            for p1 in ps:\n",
    "                tr = transitions[t]\n",
    "                key = ((\"tr\",tr),p1)\n",
    "                all_counts[key] = all_counts.get(key,0)+1\n",
    "                counts_by_time[t][key] = counts_by_time[t].get(key,0)+1\n",
    "                (_,dest) = tr\n",
    "                keystar = ((\"tr\",(\"*\",dest)),p1)\n",
    "                all_counts[keystar] = all_counts.get(keystar,0)+1\n",
    "                counts_by_time[t][keystar] = counts_by_time[t].get(keystar,0)+1\n",
    "    return all_counts, counts_by_time\n",
    "all_counts,counts_by_time = count_events(preds)\n",
    "all_cocounts,cocounts_by_time = count_coevents(preds)\n",
    "\n",
    "def count_conditional_events(preds,condition):\n",
    "    all_counts = {}\n",
    "    counts_by_time = {}\n",
    "    for t,ps in enumerate(preds):\n",
    "        counts_by_time[t] = {}\n",
    "        if condition in ps:\n",
    "            for p in ps:\n",
    "                all_counts[p] = all_counts.get(p,0)+1\n",
    "                counts_by_time[t][p] = counts_by_time[t].get(p,0)+1\n",
    "            if t in transitions:\n",
    "                tr = transitions[t]\n",
    "                key = (\"tr\",tr)\n",
    "                all_counts[key] = all_counts.get(key,0)+1\n",
    "                counts_by_time[t][key] = counts_by_time[t].get(key,0)+1\n",
    "                (_,dest) = tr\n",
    "                keystar = (\"tr\",(\"*\",dest))\n",
    "                all_counts[keystar] = all_counts.get(keystar,0)+1\n",
    "                counts_by_time[t][keystar] = counts_by_time[t].get(keystar,0)+1\n",
    "    return all_counts\n",
    "def count_joint_events(preds,conditions):\n",
    "    count = 0\n",
    "    for t,ps in enumerate(preds):\n",
    "        trans = transitions.get(t,-1)\n",
    "        is_good = True\n",
    "        for condition in conditions:\n",
    "            if condition not in ps and condition != trans:\n",
    "                is_good = False\n",
    "                break\n",
    "        if is_good:\n",
    "            count += 1\n",
    "    return count\n",
    "    \n",
    "def count_conditional_coevents(preds,condition):\n",
    "    all_counts = {}\n",
    "    counts_by_time = {}\n",
    "    for t,ps in enumerate(preds):\n",
    "        counts_by_time[t] = {}\n",
    "        if condition in ps:\n",
    "            for p1 in ps:\n",
    "                for p2 in ps:\n",
    "                    p = (p1,p2)\n",
    "                    all_counts[p] = all_counts.get(p,0)+1\n",
    "                    counts_by_time[t][p] = counts_by_time[t].get(p,0)+1\n",
    "            if t in transitions:\n",
    "                for p1 in ps:\n",
    "                    tr = transitions[t]\n",
    "                    key = ((\"tr\",tr),p1)\n",
    "                    all_counts[key] = all_counts.get(key,0)+1\n",
    "                    counts_by_time[t][key] = counts_by_time[t].get(key,0)+1\n",
    "                    (_,dest) = tr\n",
    "                    keystar = ((\"tr\",(\"*\",dest)),p1)\n",
    "                    all_counts[keystar] = all_counts.get(keystar,0)+1\n",
    "                    counts_by_time[t][keystar] = counts_by_time[t].get(keystar,0)+1\n",
    "    return all_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### tile2colorized = pickle.load(open('tile2colorized.pkl'))\n",
    "id2colorized = pickle.load(open('id2sprites.pkl'))[1]\n",
    "\n",
    "\n",
    "inv_len = 1.0/float(len(track))\n",
    "npmis = {}\n",
    "pmis = {}\n",
    "for transition in sorted(transitions):\n",
    "    transition = transitions[transition]\n",
    "    for pred in all_counts:\n",
    "        if pred != transition:\n",
    "            p1 = all_counts[pred]*inv_len\n",
    "            p2 = all_counts[(\"tr\",transition)]*inv_len\n",
    "            cooccur = ((\"tr\",transition),pred)\n",
    "            if cooccur in all_cocounts:\n",
    "                p12 = all_cocounts[cooccur]*inv_len\n",
    "            else:\n",
    "                p12 = 0.0\n",
    "            \n",
    "            if p12/(p1*p2) != 0.0:\n",
    "                if transition not in npmis:\n",
    "                    npmis[transition] = {}\n",
    "                pmis[(transition,pred)] = np.log(p12/(p1*p2))\n",
    "                npmis[transition][np.log(p12/(p1*p2))/-np.log(p12)] = pred\n",
    "\n",
    "for t in sorted(npmis):\n",
    "    for pmi in reversed(sorted(npmis[t])):\n",
    "        if pmi > 0.4:\n",
    "            e1 =  npmis[t][pmi]\n",
    "            conditioned_px = count_conditional_events(preds,e1)\n",
    "            conditioned_pxy = count_conditional_coevents(preds,e1)\n",
    "            print t, npmis[t][pmi], pmi, e1\n",
    "            if False:\n",
    "                for pmi2 in reversed(sorted(npmis[t])):\n",
    "                    if pmi != pmi2:\n",
    "                        e2 =  npmis[t][pmi2]\n",
    "                        pmi_t_e1 = pmis[(t,e1)]\n",
    "\n",
    "\n",
    "                        p_t_e2_I_e1 = conditioned_pxy.get(((\"tr\",t),e2),0)/float(all_counts[e1])\n",
    "                        p_t_I_e1 = conditioned_px.get((\"tr\",t),0)/float(all_counts[e1])\n",
    "                        p_e2_I_e1 = conditioned_px.get(e2,0)/float(all_counts[e1])\n",
    "                        if p_t_I_e1 == 0.0 or p_e2_I_e1 == 0.0:\n",
    "                            p_t_e2_I_e1 = 0.0\n",
    "                            p_t_I_e1 = 1\n",
    "                            p_e2_I_e1 = 1\n",
    "\n",
    "                        pmi_t_e1_e2 = (pmi_t_e1 + np.log(p_t_e2_I_e1/(p_t_I_e1*p_e2_I_e1)))\n",
    "\n",
    "                        p_t_e1_e2 = count_joint_events(preds,[e1,e2,t])*inv_len\n",
    "                        if p_t_e1_e2 == 0.0:\n",
    "                            npmi_t_e1_e2 = -1.0\n",
    "                        else:\n",
    "                            npmi_t_e1_e2 = pmi_t_e1_e2/-np.log(p_t_e1_e2)\n",
    "                        if npmi_t_e1_e2 > 0.0:\n",
    "                            print 'pmi({};{},{})'.format(t,e1,e2), npmi_t_e1_e2, pmi,pmi2\n",
    "                            if 'col' in e2 and 'tile' in e2[1][0]:\n",
    "                                plt.imshow(tile2colorized[e2[1][0][:2]]/255.)\n",
    "                                plt.show()\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevance_threshold = 0.1\n",
    "universality_threshold = 0.8\n",
    "negation_threshold = -1.0\n",
    "\n",
    "for tr,pred_npmis in npmis.items():# + paired_npmis.items():\n",
    "    if tr[1] != 5: continue\n",
    "\n",
    "    cond_probs = {k: cond_prob(list(k), (\"tr\",tr), all_counts, counts_by_time) for k in pred_npmis.keys()}\n",
    "    #print pred_npmis\n",
    "    relevants = {k: npmi for (k,npmi) in pred_npmis.items() if npmi >= relevance_threshold}\n",
    "    negations = {k: npmi for (k,npmi) in pred_npmis.items() if npmi <= negation_threshold}\n",
    "    conjuncts = set(filter(lambda k:cond_probs[k] >= universality_threshold, relevants.keys()))\n",
    "    disjuncts = set(filter(lambda k:cond_probs[k] < universality_threshold, relevants.keys()))\n",
    "    print \"-------\\nTransition:\",tr\n",
    "    print \"\\n\".join(map(str,cond_probs.items()))\n",
    "    print \"-----\\nRelevant:\\n\",\"\\n\".join(map(str,relevants.keys()))\n",
    "    print \"-----\\nConjuncts:\\n\",\" & \".join(map(str,conjuncts))\n",
    "    print \"-----\\nDisjuncts:\\n\",\" | \".join(map(str,disjuncts))\n",
    "    print \"-----\\nNegations:\\n\",\" & \".join(map(lambda k:\"~\" + str(k),negations))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump((npmis, paired_npmis, entries, entries_from, new_preds, modes, merged, unions, track, inputVec, all_times), \n",
    "            open(\"edges.pkl\",'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
