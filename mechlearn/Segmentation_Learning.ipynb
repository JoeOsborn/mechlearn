{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cpu,floatX=float32\"\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import math\n",
    "import networkx as nx\n",
    "import nxpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(start_time, end_time, axis, all_times, track, velocities, inputVec, likes) = pickle.load(open(\"mario_likes.pkl\"))\n",
    "limit = 100\n",
    "chunks = 10\n",
    "chunk_data = []\n",
    "for chunki in range(0, chunks):\n",
    "    chunk_data.append(pickle.load(\n",
    "        open(\"mario_{}_{}_{}.like.pkl\".format(limit, chunki, chunks))\n",
    "    ))\n",
    "    print \"Loaded {}/{}\".format(chunki, chunks)\n",
    "\n",
    "(start, _cend, axis, all_times, track,\n",
    " velocities, inputVec, _likes) = chunk_data[0]\n",
    "(_lastStart, end_time, _axis, _all_times, _track,\n",
    " _velocities, _inputVec, _lastLikes) = chunk_data[-1]\n",
    "\n",
    "likes = [None] * end_time\n",
    "\n",
    "# Janky as heck but a straightforward way to load up models built in parallel\n",
    "\n",
    "for (cstart, cend, axis, all_times, track, velocities, inputVec, clikes) in chunk_data:\n",
    "    likes[cstart:cend] = clikes[cstart:cend]\n",
    "\n",
    "print \"Loaded\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Templates is an array of model-generating functions of increasing complexity.\n",
    "templates = [\n",
    "    # Constant 0 velocity\n",
    "    (\"c0\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n, \n",
    "        mu=0,\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "    # Constant velocity from old value\n",
    "    (\"cP\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n,\n",
    "        mu=pv,\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "    # Fixed constant velocity\n",
    "    (\"cN\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n,\n",
    "        mu=pm.Normal(n+\"_N\",mu=0,sd=10),\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "    # Constant acceleration from 0\n",
    "    (\"acc0\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n,\n",
    "        mu=pm.Normal(n+\"_acc\",mu=0,sd=10)*vs[:,0],\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "    # Constant acceleration from old velocity value\n",
    "    (\"accP\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n,\n",
    "        mu=pv+pm.Normal(n+\"_acc\",mu=0,sd=10)*vs[:,0],\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "    # Constant acceleration from fixed constant velocity\n",
    "    (\"accN\",lambda n,axis,vs,pv: pm.Normal(\n",
    "        n,\n",
    "        mu=pm.Normal(n+\"_N\",mu=0,sd=10)+pm.Normal(n+\"_acc\",mu=0,sd=20)*vs[:,0],\n",
    "        sd=pm.HalfCauchy(n+\"_err\",beta=10),\n",
    "        observed=vs[:,axis]\n",
    "    )),\n",
    "]\n",
    "templates = templates\n",
    "type2ind = {t[0]:i for i,t in enumerate(templates)}\n",
    "print type2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations = 5000\n",
    "def model_template_generate(template_i, axis, segment, prev_val):\n",
    "    axisNames = [None,\"x\",\"y\"]\n",
    "    template = templates[template_i]\n",
    "    (tn, t) = template\n",
    "    with pm.Model() as model:\n",
    "        lik = t(axisNames[axis],axis,segment,prev_val)\n",
    "        step = pm.Metropolis()\n",
    "        trace = pm.sample(iterations, step, progressbar=True)\n",
    "        subtrace = trace[len(trace)/2:-1:10]\n",
    "    return (tn,model,subtrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# What is the mode as of just before each switch-point, \n",
    "# and what is the accumulated cost of the approximation up to that point?\n",
    "modes = [(0,None)]*(len(all_times))\n",
    "\n",
    "#modes is offset from likes by 1\n",
    "\n",
    "ks = {\"c0\":1, \"cP\":1, \"cN\":2, \"acc0\":2, \"accP\":2, \"accN\":3}\n",
    "\n",
    "# TODO: Tweak me and then make sure that helped the situation below\n",
    "cost = 10\n",
    "\n",
    "# Takahashi Meijin constant, 60 frames / 16 inputs ~= 4 frames per input.\n",
    "# But note that in general transitions may happen more frequently due to collisions, etc.\n",
    "min_interval = 4 \n",
    "\n",
    "all_times_ = all_times\n",
    "all_times = all_times_[:30]\n",
    "\n",
    "for j in range(1, len(all_times)):\n",
    "    least = float(\"inf\")\n",
    "    least_template = None\n",
    "    print \"j\",j\n",
    "    for i in range(0, j):\n",
    "        data = likes[i][j]\n",
    "        if not data:\n",
    "            print \"skip\",i,j,all_times[i],all_times[j]\n",
    "            continue\n",
    "        dt = data[3]-data[2]\n",
    "#         if dt < min_interval:\n",
    "#             print \"skip min\",data[:4]\n",
    "#             continue\n",
    "        the_templates = data[-1]\n",
    "        print \"i\",i\n",
    "        for tn,mod,trace in the_templates:\n",
    "            k = ks[tn]\n",
    "            summary = pm.df_summary(trace)\n",
    "            logp = np.mean([mod.logp(pt) for pt in trace])\n",
    "            # WAIC\n",
    "            #crit = -pm.stats.waic(model=mod,trace=trace)\n",
    "            # DIC\n",
    "            # crit = pm.stats.dic(model=mod,trace=trace)\n",
    "            # if np.abs(crit) > 1e5:\n",
    "            #     crit = float('inf')\n",
    "            # BPIC\n",
    "            #crit = pm.stats.bpic(model=mod,trace=trace)\n",
    "            # AICc\n",
    "            #crit = 2*k - 2 * logp + (2*(k+1)*(k+2))/(dt-k-2)\n",
    "            # BIC\n",
    "            crit = math.log(dt)*k - 2 * logp\n",
    "            # max-likelihood\n",
    "            #crit = -logp\n",
    "            \n",
    "            #crit = math.log(dt) - logp\n",
    "            m_prev = modes[i][0]\n",
    "            # ??\n",
    "            # crit = summary[\"mean\"][\"y_err\"]*dt\n",
    "            penalty = 0\n",
    "            if dt < min_interval:\n",
    "                # TODO drop me??  or make me much bigger?\n",
    "                penalty = cost\n",
    "                print \"penalize too short\",data[:4],crit,crit+m_prev+cost,crit + m_prev + cost + penalty\n",
    "            here = crit + m_prev + cost + penalty\n",
    "            print i,j,data[2],data[3],tn,logp,summary[\"mean\"][\"y_err\"],crit,here,least\n",
    "            if here < least:\n",
    "                print \"update least\",here\n",
    "                least = here\n",
    "                # prev_i,this_j,t0,t1,name,summary,criterion\n",
    "                least_template = (i,j,data[2],data[3],tn,summary,crit)\n",
    "    assert least_template != None\n",
    "    modes[j] = (least, least_template)\n",
    "\n",
    "print map(lambda m:m,modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_path(modes):\n",
    "    mj = len(modes)-1\n",
    "    path = [modes[mj]]\n",
    "    while mj > 0:\n",
    "        print modes[mj]\n",
    "        mj = modes[mj][1][0]\n",
    "        path.append(modes[mj])\n",
    "    return list(reversed(path))[1:]\n",
    "\n",
    "path = get_path(modes)\n",
    "for ii,p in enumerate(path):\n",
    "    print ii,p[0],'\\n',p[1],'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"UnionFind.py\n",
    "\n",
    "Union-find data structure. Based on Josiah Carlson's code,\n",
    "http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/215912\n",
    "with significant additional changes by D. Eppstein.\n",
    "\"\"\"\n",
    "\n",
    "class UnionFind:\n",
    "    \"\"\"Union-find data structure.\n",
    "\n",
    "    Each unionFind instance X maintains a family of disjoint sets of\n",
    "    hashable objects, supporting the following two methods:\n",
    "\n",
    "    - X[item] returns a name for the set containing the given item.\n",
    "      Each set is named by an arbitrarily-chosen one of its members; as\n",
    "      long as the set remains unchanged it will keep the same name. If\n",
    "      the item is not yet part of a set in X, a new singleton set is\n",
    "      created for it.\n",
    "\n",
    "    - X.union(item1, item2, ...) merges the sets containing each item\n",
    "      into a single larger set.  If any item is not yet part of a set\n",
    "      in X, it is added to X as one of the members of the merged set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Create a new empty union-find structure.\"\"\"\n",
    "        self.weights = {}\n",
    "        self.parents = {}\n",
    "\n",
    "    def __getitem__(self, object):\n",
    "        \"\"\"Find and return the name of the set containing the object.\"\"\"\n",
    "\n",
    "        # check for previously unknown object\n",
    "        if object not in self.parents:\n",
    "            self.parents[object] = object\n",
    "            self.weights[object] = 1\n",
    "            return object\n",
    "\n",
    "        # find path of objects leading to the root\n",
    "        path = [object]\n",
    "        root = self.parents[object]\n",
    "        while root != path[-1]:\n",
    "            path.append(root)\n",
    "            root = self.parents[root]\n",
    "\n",
    "        # compress the path and return\n",
    "        for ancestor in path:\n",
    "            self.parents[ancestor] = root\n",
    "        return root\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate through all items ever found or unioned by this structure.\"\"\"\n",
    "        return iter(self.parents)\n",
    "\n",
    "    def union(self, *objects):\n",
    "        \"\"\"Find the sets containing the objects and merge them all.\"\"\"\n",
    "        roots = [self[x] for x in objects]\n",
    "        heaviest = max([(self.weights[r],r) for r in roots])[1]\n",
    "        for r in roots:\n",
    "            if r != heaviest:\n",
    "                self.weights[heaviest] += self.weights[r]\n",
    "                self.parents[r] = heaviest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross = {}\n",
    "\n",
    "for ii,mode in enumerate(path):\n",
    "    d = {t[0]:t[1:] for t in likes[mode[1][0]][mode[1][1]][4]}\n",
    "    model,trace = {t[0]:t[1:] for t in likes[mode[1][0]][mode[1][1]][4]}[mode[1][4]]\n",
    "    for jj,mode2 in enumerate(path):\n",
    "        model2,trace2 = {t[0]:t[1:] for t in likes[mode2[1][0]][mode2[1][1]][4]}[mode2[1][4]]\n",
    "        if mode2[1][4] == mode[1][4]:\n",
    "            try:\n",
    "                crit = -np.mean([model.logp(pt) for pt in trace2])#pm.stats.dic(model=model,trace=trace2)\n",
    "            except:\n",
    "                crit = float('inf')\n",
    "        else:\n",
    "            crit = float('inf')\n",
    "        cross[(ii,jj)] = crit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complexityWeight = 20\n",
    "unions = UnionFind()\n",
    "for d in sorted(cross):\n",
    "    good = True\n",
    "    for t in [cross[d], cross[(d[0],d[0])], cross[(d[1],d[1])], cross[(d[1],d[0])]]:\n",
    "        if t == float('inf'):\n",
    "            good = False\n",
    "    if not good:\n",
    "        continue\n",
    "    joined = min(cross[d] + cross[(d[0],d[0])],cross[(d[1],d[1])]+cross[(d[1],d[0])])\n",
    "    \n",
    "    if (joined < (cross[(d[0],d[0])]+cross[(d[1],d[1])]) +complexityWeight):\n",
    "        unions.union(d[0],d[1])\n",
    "merged = {}\n",
    "for u in unions:\n",
    "    #print u, unions[u]\n",
    "    if unions[u] not in merged:\n",
    "        merged[unions[u]] = set()\n",
    "    merged[unions[u]].add(u)\n",
    "print len(merged)\n",
    "print \"\\n\".join(map(lambda m:str((m,path[m][1][:5],path[m][1][5][\"mean\"].to_dict())),merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 1000\n",
    "\n",
    "def model_sets_generate2(ti,data):\n",
    "    track,all_times,axis,i,j = data\n",
    "    segments = []\n",
    "    for ind in range(len(i)):\n",
    "        t0 = all_times[i[ind]]\n",
    "        t1 = all_times[j[ind]]\n",
    "        if t0 == 0:\n",
    "            segment = track[t0+1:t1+1]-track[t0:t1]\n",
    "            prev_vel = 0\n",
    "        elif t1+1 > np.shape(track)[1]:\n",
    "            extended_track = np.concatenate((track,[track[-1]]))\n",
    "            segment = extended_track[t0+1:t1+1]-extended_track[t0:t1]\n",
    "            prev_vel = track[t0,axis]-track[t0-1,axis]\n",
    "        else:\n",
    "            #9,10,11 - 8,9,10\n",
    "            segment = track[t0+1:t1+1]-track[t0:t1]\n",
    "            prev_vel = track[t0,axis]-track[t0-1,axis]\n",
    "        segment[:,0] = range(0,np.shape(segment)[0])\n",
    "        segments.append(segment)\n",
    "    segment = np.vstack(segments)\n",
    "    result = model_template_generate(ti, \n",
    "                                       axis,\n",
    "                                       segment,\n",
    "                                       prev_vel)\n",
    "    return (i,j,t0,t1,result)\n",
    "\n",
    "# for m in merged:\n",
    "#     print ''\n",
    "#     if len(merged[m]) > 1:\n",
    "#         i_ = []\n",
    "#         j_ = []\n",
    "#         for t in merged[m]:\n",
    "#             mode = path[t]\n",
    "#             dat = likes[mode[1][0]][mode[1][1]]\n",
    "#             ti = type2ind[mode[1][4]]\n",
    "#             i_.append(dat[0])\n",
    "#             j_.append(dat[1])\n",
    "#         result = model_sets_generate2(ti,(track,all_times,axis,i_,j_))\n",
    "#         print m,result\n",
    "#         #pm.summary(result[4][2])\n",
    "#         #print pm.df_summary(result[4][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = ['r','g','b','c','m','y','k',\"#aa0000\",\"#00aa00\",\"#0000aa\",\"#880000\",\"#008800\",\"#000088\"]\n",
    "merged2color = {m:i for i,m in enumerate(sorted(merged))}\n",
    "\n",
    "for m in merged:\n",
    "    for t in merged[m]:\n",
    "        plt.plot(np.array(path[t][1][2:4]),np.array([m,m]),colors[merged2color[m]])\n",
    "\n",
    "plt.plot(velocities[:all_times[-1]])\n",
    "plt.plot(np.array(all_times),velocities[np.array(all_times,dtype='int')],'rx')\n",
    "plt.xlim((50,120))\n",
    "plt.show()\n",
    "\n",
    "# Interestingly, we have \"on the ground for a litle bit\" and \"on the ground for longer\" as different modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = 270\n",
    "transitions = {}\n",
    "# Edges into [outer] from [inner]\n",
    "entries_from = {m: {m: [] for m in merged} \n",
    "                for m in merged}\n",
    "# Edges into [outer]\n",
    "entries = {m: [] for m in merged}\n",
    "for t in range(1,len(path)):\n",
    "    if t == 0:\n",
    "        prev = -1\n",
    "    else:\n",
    "        prev = unions[t-1]\n",
    "\n",
    "    start = path[t][1][2]\n",
    "    entries_from[unions[t]][prev].append(start)\n",
    "    entries[unions[t]].append(start)\n",
    "    transitions[start] = (prev,unions[t])\n",
    "    print (path[t][1][0],start),\":\",prev,\"->\",unions[t],\"\\n\",path[unions[t]][1][4],path[unions[t]][1][5][\"mean\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = nx.MultiDiGraph()\n",
    "for tgt,srcs in entries_from.items():\n",
    "    G.add_node(tgt,label=str(tgt))\n",
    "    # Let's learn about tgt\n",
    "    mtype = path[tgt][1][4]\n",
    "    params = path[tgt][1][5][\"mean\"].to_dict()\n",
    "    params[\"type\"] = mtype\n",
    "    for k,v in sorted(params.items()):\n",
    "#         if k == \"y_err\":\n",
    "#             continue\n",
    "        G.node[tgt][\"label\"] = (G.node[tgt][\"label\"] + \"\\n\" + str((k,v)))\n",
    "    print tgt,params\n",
    "    for src,times in srcs.items():\n",
    "        for t in times:\n",
    "            G.add_edge(src,tgt,label=t)\n",
    "\n",
    "G.add_node(-1)\n",
    "G.add_edge(-1, unions[0])\n",
    "\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collisions = pickle.load(open('mario_collisions.pkl'))\n",
    "\n",
    "def button_changes(button_masks):\n",
    "    last_mask = 0\n",
    "    mask_times = {}\n",
    "    for t, b in enumerate(button_masks):\n",
    "        b_ = int(b)\n",
    "        buttons = []\n",
    "        for ii,c in enumerate(list('RLDUTSBA')):\n",
    "            if b_ & (1 << (7-ii)):\n",
    "                buttons.append(c)\n",
    "        l_ = int(last_mask)\n",
    "        last_buttons = []\n",
    "        for ii,c in enumerate(list('RLDUTSBA')):\n",
    "            if l_ & (1 << (7-ii)):\n",
    "                last_buttons.append(c)\n",
    "        mask_times[t] = (tuple(last_buttons),tuple(buttons))\n",
    "        last_mask = b\n",
    "    \n",
    "    return mask_times\n",
    "\n",
    "button_change_times = button_changes(inputVec)\n",
    "for t in sorted(button_change_times):\n",
    "    print t, button_change_times[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sign(num):\n",
    "    if num < 0:\n",
    "        return -1\n",
    "    if num > 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def button_diff(btnsA, btnsB):\n",
    "    return set(btnsA) - set(btnsB)\n",
    "\n",
    "def button_intersect(btnsA, btnsB):\n",
    "    return set(btnsA) & set(btnsB)\n",
    "\n",
    "def button_union(btnsA, btnsB):\n",
    "    return set(btnsA) | set(btnsB)\n",
    "\n",
    "def button_preds(button_pairs):\n",
    "    here_i = set()\n",
    "    for bp in button_pairs:\n",
    "        released_i = button_diff(bp[0], bp[1])\n",
    "        pressed_i = button_diff(bp[1], bp[0])    \n",
    "        held_i = bp[1]\n",
    "        for ri in released_i:\n",
    "            here_i.add((\"release\",ri))\n",
    "        for ri in pressed_i:\n",
    "            here_i.add((\"press\",ri))\n",
    "        for ri in held_i:\n",
    "            here_i.add((\"hold\",ri))\n",
    "    return list(here_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = [set()]*len(velocities)\n",
    "for t in range(0,len(velocities)):\n",
    "    psi = ([button_change_times[start_time+t+i]\n",
    "            for i in range(0, 1)],\n",
    "            #  TODO: stopped colliding/started colliding?  That would mean\n",
    "           #   I could say \"started colliding with X on bottom and also zin,-1\"\n",
    "           #   to help find solid things.\n",
    "           #     ... no... acc,0 should be enough (walking right across solid tiles)\n",
    "           #     but I should also consider \n",
    "           #     a more sophisticated notion of collision.\n",
    "           #      e.g. \"bottom\" is good but it should be the lowest bottom tile.\n",
    "           #      how can I get that?  can I get that?\n",
    "           #      (OTOH, maybe this isn't even necessary if e.g. \"touching my feet against sky\"\n",
    "          #        doesn't cause vy=0 as often as \"touching my feet against ground\" does. so let's be\n",
    "          #         sure that's surfaced!)\n",
    "            (collisions.get(start_time+t,set())),\n",
    "            (velocities[t-1],velocities[t])\n",
    "          )\n",
    "    buttons_i = psi[0]\n",
    "    here_i = button_preds(buttons_i)\n",
    "    for coli in psi[1]:\n",
    "        here_i.append((\"col\",coli))\n",
    "    vel0,vel1 = psi[2]\n",
    "    if vel0 < vel1:\n",
    "        here_i.append((\"acc\",1))\n",
    "    if vel0 > vel1:\n",
    "        here_i.append((\"acc\",-1))\n",
    "    if vel0 == vel1:\n",
    "        here_i.append((\"acc\",0))\n",
    "    if vel1 < 0:\n",
    "        here_i.append((\"vel\",-1))\n",
    "    if vel1 > 0:\n",
    "        here_i.append((\"vel\",1))\n",
    "    if vel1 == 0:\n",
    "        here_i.append((\"vel\",0))\n",
    "    if vel0 < 0 and vel1 > 0:\n",
    "        here_i.append((\"zc\",1))\n",
    "    if vel0 > 0 and vel1 < 0:\n",
    "        here_i.append((\"zc\",-1))\n",
    "    if vel0 < 0 and vel1 == 0:\n",
    "        here_i.append((\"zin\",1))\n",
    "    if vel0 > 0 and vel1 == 0:\n",
    "        here_i.append((\"zin\",-1))\n",
    "    if vel0 == 0 and vel1 < 0:\n",
    "        here_i.append((\"zout\",-1))\n",
    "    if vel0 == 0 and vel1 > 0:\n",
    "        here_i.append((\"zout\",1))\n",
    "    preds[t] = set(here_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to use NPMI to figure out which conditions are likely to be important to the learned transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_cooccurrences(pred_sets,ignored):\n",
    "    ocs = {}\n",
    "    coocs = {}\n",
    "    nice_pred_sets = []\n",
    "    for pi in range(0, len(pred_sets)):\n",
    "        here_i = pred_sets[pi]\n",
    "        here_i = list(set(here_i) - ignored)\n",
    "        for pred in here_i:\n",
    "            ocs[pred] = ocs.get(pred,0)+1\n",
    "        for predii in range(0,len(here_i)):\n",
    "            if here_i[predii] not in coocs:\n",
    "                coocs[here_i[predii]] = {}\n",
    "            for predij in range(0,len(here_i)):\n",
    "                coocs[here_i[predii]][here_i[predij]] = coocs[here_i[predii]].get(here_i[predij],0)+1\n",
    "        nice_pred_sets.append(here_i)\n",
    "    return nice_pred_sets,ocs,coocs\n",
    "\n",
    "\n",
    "def calc_npmi(pred_sets, ocs, coocs):\n",
    "    maximum = float(len(pred_sets))\n",
    "    npmis = {}\n",
    "    probs = {}\n",
    "    # How likely are individual predicates to co-occur \n",
    "    #  within the transitions to a given target?\n",
    "    for predx,countx in ocs.items():\n",
    "        px = countx / maximum\n",
    "        probs[predx] = px\n",
    "        for predy,countxy in coocs[predx].items():\n",
    "            py = ocs[predy] / maximum\n",
    "            pxy = countxy / maximum\n",
    "            d = (math.log(px*py)/math.log(pxy) - 1) if pxy != 1 else 1\n",
    "            npmis[(predx,predy)] = d\n",
    "    return probs,npmis\n",
    "\n",
    "def calc_npmi_pred_edge(all_ocs, all_edge_ocs, edge_count, all_edge_count):\n",
    "    npmis = {}\n",
    "    probs = {}\n",
    "    # How likely are individual predicates to co-occur \n",
    "    #  within the transitions to a given target?\n",
    "    for predx,countx in all_ocs.items():\n",
    "        px = countx / float(all_edge_count)\n",
    "        py = edge_count / float(all_edge_count)\n",
    "        pxy = all_edge_ocs.get(predx,0) / float(all_edge_count)\n",
    "        probs[predx] = all_edge_ocs.get(predx,0) / float(edge_count)\n",
    "        assert px <= 1, (px,countx,all_edge_count)\n",
    "        assert py <= 1, (py,edge_count,all_edge_count)\n",
    "        assert pxy <= 1, (pxy,all_edge_ocs.get(predx,0),float(edge_count))\n",
    "        if pxy == 0:\n",
    "            d = -1\n",
    "        elif pxy == 1:\n",
    "            d = 1\n",
    "        else:\n",
    "            d = (math.log(px*py)/math.log(pxy) - 1)\n",
    "        npmis[predx] = d\n",
    "    return probs,npmis\n",
    "\n",
    "def calc_npmi(pred1, pred2, all_counts, counts_by_time):\n",
    "    norm = float(len(counts_by_time)+1)\n",
    "    count1 = all_counts[pred1]\n",
    "    count2 = all_counts[pred2]\n",
    "    count12 = 0\n",
    "    for t,cs in counts_by_time.items():\n",
    "        count12 += cs.get(pred1,0) * cs.get(pred2,0)\n",
    "    p1 = count1 / norm\n",
    "    p2 = count2 / norm\n",
    "    p12 = count12 / norm\n",
    "    if p12 == 0:\n",
    "        d = -1\n",
    "    elif p12 == 1:\n",
    "        d = 1\n",
    "    else:\n",
    "        d = math.log(p1*p2)/math.log(p12) - 1\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_events(preds):\n",
    "    all_counts = {}\n",
    "    counts_by_time = {}\n",
    "    for t,ps in enumerate(preds):\n",
    "        counts_by_time[t] = {}\n",
    "        for p in ps:\n",
    "            all_counts[p] = all_counts.get(p,0)+1\n",
    "            counts_by_time[t][p] = counts_by_time[t].get(p,0)+1\n",
    "        if t in transitions:\n",
    "            tr = transitions[t]\n",
    "            key = (\"tr\",tr)\n",
    "            all_counts[key] = all_counts.get(key,0)+1\n",
    "            counts_by_time[t][key] = counts_by_time[t].get(key,0)+1\n",
    "            (_,dest) = tr\n",
    "            keystar = (\"tr\",(\"*\",dest))\n",
    "            all_counts[keystar] = all_counts.get(keystar,0)+1\n",
    "            counts_by_time[t][keystar] = counts_by_time[t].get(keystar,0)+1\n",
    "    return all_counts, counts_by_time\n",
    "\n",
    "all_counts,counts_by_time = count_events(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's figure out which tiles block movement on which sides!\n",
    "# co-occurrence of (col, BLAH) and acc0 for each BLAH.\n",
    "# cluster together tiles which block on a given side (for now, all those with co-occurrence over threshold)\n",
    "# then add new preds!\n",
    "\n",
    "def cond_prob(e1s, e2, all_counts, counts_by_time):\n",
    "    p2 = all_counts[e2]/float(len(counts_by_time))\n",
    "    count12 = 0\n",
    "    for t,cs in counts_by_time.items():\n",
    "        any_e1_present = False\n",
    "        for e1 in e1s:\n",
    "            if e1 in cs:\n",
    "                any_e1_present = True\n",
    "                break\n",
    "        if any_e1_present and (e2 in cs):\n",
    "            count12 += 1\n",
    "    p12 = count12 / float(len(counts_by_time))\n",
    "    return p12 / p2\n",
    "\n",
    "block_chance = {}\n",
    "for thing,count in all_counts.items():\n",
    "    # TODO: generalize back to all sides, but note \"colliding on right with something\" -> \"vely=0\" is not that sensible.\n",
    "    #  need a notion of acc,vel,zin,zout and _other axis_ acc,vel,zin,zout.\n",
    "    if thing[0] != \"col\" or thing[1][1] != \"bottom\": \n",
    "        continue\n",
    "    block_chance[thing] = cond_prob([(\"vel\",0),(\"acc\",0)], \n",
    "                                    thing,\n",
    "                                    all_counts,\n",
    "                                    counts_by_time)\n",
    "\n",
    "merged_by_side = {}\n",
    "# TODO: generalize back to all sides\n",
    "for side in [\"bottom\"]:\n",
    "    blockings = filter(lambda (col,prob):(col[1][0][0] != \"solid\" and \n",
    "                                          col[1][1] == side and \n",
    "                                          prob > 0.8),\n",
    "                       block_chance.items())\n",
    "    merged_by_side[side] = set()\n",
    "    for bcol,bprob in blockings:\n",
    "        merged_by_side[side].add(bcol)\n",
    "block_chance,merged_by_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's add new preds now!\n",
    "new_preds = [set() for i in range(0,len(preds))]\n",
    "for t,pset in enumerate(preds):\n",
    "    for side,equiv in merged_by_side.items():\n",
    "        found = False\n",
    "        for pred in pset:\n",
    "            new_preds[t].add(pred)\n",
    "            if not found and pred[0] == \"col\" and pred[1] in equiv:\n",
    "                pset.append((\"col\", ((\"solid\", equiv), side)))\n",
    "                found = True\n",
    "all_counts,counts_by_time = count_events(new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's calculate NPMI between predicates and transitions!\n",
    "npmis = {}\n",
    "for thing,count in all_counts.items():\n",
    "    if thing[0] == \"tr\":\n",
    "        print \"tr:\",thing,count\n",
    "        tr = thing[1]\n",
    "        # Find NPMI with every predicate\n",
    "        for thing2,count in all_counts.items():\n",
    "            if thing2[0] == \"tr\":\n",
    "                continue\n",
    "            if tr not in npmis:\n",
    "                npmis[tr] = {}\n",
    "            npmis[tr][thing2] = calc_npmi(thing, \n",
    "                                          thing2, \n",
    "                                          all_counts,\n",
    "                                          counts_by_time)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for tr,prednpmis in npmis.items():\n",
    "    print \"----\"\n",
    "    print tr\n",
    "    print \"----\"\n",
    "    for pred,pmi in sorted(prednpmis.items(),\n",
    "                           lambda a,b:sign(b[1]-a[1])):\n",
    "        print pred,pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_npmi_chained(e1,e2,e3,all_counts,counts_by_time):\n",
    "    p1 = all_counts[e1] / float(len(counts_by_time)+1)\n",
    "    p2 = all_counts[e2] / float(len(counts_by_time)+1)\n",
    "    if p1 == 0:\n",
    "        assert(False)\n",
    "        print \"p1=0\"\n",
    "        return -1\n",
    "    if p2 == 0:\n",
    "        assert(False)\n",
    "        print \"p2=0\"\n",
    "        return -1\n",
    "    count12 = 0\n",
    "    for t,cs in counts_by_time.items():\n",
    "        if (e1 in cs) and (e2 in cs):\n",
    "            count12 += 1\n",
    "    p12 = count12 / float(len(counts_by_time)+1)\n",
    "    if p12 == 0:\n",
    "        # Never co-occur, avoid log(0)\n",
    "        return -1\n",
    "    pmi12 = math.log(p12 / (p1 * p2))\n",
    "    #p(event ,  causeB| causeA)/ (p(event) * p(causeB|causeA))\n",
    "    times_1_and_3_and_2_happen = 0\n",
    "    times_3_and_2_happen = 0\n",
    "    times_any_happen = 0\n",
    "    for t,cs in counts_by_time.items():\n",
    "        if (e1 in cs) and (e3 in cs) and (e2 in cs):\n",
    "            times_1_and_3_and_2_happen += 1\n",
    "        if (e3 in cs) and (e2 in cs):\n",
    "            times_3_and_2_happen += 1\n",
    "        if (e1 in cs) or (e2 in cs) or (e3 in cs):\n",
    "            times_any_happen += 1\n",
    "    p132 = times_1_and_3_and_2_happen/float(len(counts_by_time)+1)\n",
    "    if p132 == 0:\n",
    "        # Never co-occur, avoid log(0)\n",
    "        return -1\n",
    "    p13_2 = (p132/p2)\n",
    "    p32 = times_3_and_2_happen / float(len(counts_by_time)+1)\n",
    "    p3_2 = p32/p2\n",
    "    if p13_2 == 0:\n",
    "        # Never co-occur, avoid log(0)\n",
    "        return -1\n",
    "    elif p3_2 == 0:\n",
    "        # Never co-occur, avoid log(0)\n",
    "        return -1\n",
    "    pmi1_23 = math.log(p13_2/(p1 * p3_2))\n",
    "    # normalize by log(p(event;causeA;causeB))??? no...\n",
    "    # Normalize by self-information!\n",
    "    return (pmi12 + pmi1_23)/(2*(-math.log(p132)))\n",
    "\n",
    "# Let's calculate the NPMI of causal pairs with each transition!\n",
    "paired_npmis = {}\n",
    "for thing,count in all_counts.items():\n",
    "    if thing[0] == \"tr\":\n",
    "        print \"tr:\",thing,count\n",
    "        tr = thing[1]\n",
    "        if tr not in paired_npmis:\n",
    "            paired_npmis[tr] = {}\n",
    "        # Find NPMI with every predicate\n",
    "        for thing2,count2 in all_counts.items():\n",
    "            if thing2[0] == \"tr\":\n",
    "                continue\n",
    "            for thing3,count3 in all_counts.items():\n",
    "                if thing3[0] == \"tr\" or thing3 == thing2:\n",
    "                    continue\n",
    "                key = (thing2,thing3)\n",
    "                paired_npmis[tr][key] = calc_npmi_chained(thing,\n",
    "                                                          thing2,\n",
    "                                                          thing3,\n",
    "                                                          all_counts,\n",
    "                                                          counts_by_time)                \n",
    "        print \"\\n\".join(\n",
    "            map(str,\n",
    "                sorted(filter(\n",
    "                        lambda (k,v): v > 0,\n",
    "                        paired_npmis[tr].items()),\n",
    "                       lambda a,b:sign(b[1]-a[1]))))\n",
    "    else:\n",
    "        pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
