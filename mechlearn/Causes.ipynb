{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import fceulib\n",
    "import networkx as nx\n",
    "import nxpd\n",
    "import sets\n",
    "# TODO: UnionFind, probably via import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"UnionFind.py\n",
    "\n",
    "Union-find data structure. Based on Josiah Carlson's code,\n",
    "http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/215912\n",
    "with significant additional changes by D. Eppstein.\n",
    "\"\"\"\n",
    "\n",
    "class UnionFind:\n",
    "    \"\"\"Union-find data structure.\n",
    "\n",
    "    Each unionFind instance X maintains a family of disjoint sets of\n",
    "    hashable objects, supporting the following two methods:\n",
    "\n",
    "    - X[item] returns a name for the set containing the given item.\n",
    "      Each set is named by an arbitrarily-chosen one of its members; as\n",
    "      long as the set remains unchanged it will keep the same name. If\n",
    "      the item is not yet part of a set in X, a new singleton set is\n",
    "      created for it.\n",
    "\n",
    "    - X.union(item1, item2, ...) merges the sets containing each item\n",
    "      into a single larger set.  If any item is not yet part of a set\n",
    "      in X, it is added to X as one of the members of the merged set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Create a new empty union-find structure.\"\"\"\n",
    "        self.weights = {}\n",
    "        self.parents = {}\n",
    "\n",
    "    def __getitem__(self, object):\n",
    "        \"\"\"Find and return the name of the set containing the object.\"\"\"\n",
    "\n",
    "        # check for previously unknown object\n",
    "        if object not in self.parents:\n",
    "            self.parents[object] = object\n",
    "            self.weights[object] = 1\n",
    "            return object\n",
    "\n",
    "        # find path of objects leading to the root\n",
    "        path = [object]\n",
    "        root = self.parents[object]\n",
    "        while root != path[-1]:\n",
    "            path.append(root)\n",
    "            root = self.parents[root]\n",
    "\n",
    "        # compress the path and return\n",
    "        for ancestor in path:\n",
    "            self.parents[ancestor] = root\n",
    "        return root\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate through all items ever found or unioned by this structure.\"\"\"\n",
    "        return iter(self.parents)\n",
    "\n",
    "    def union(self, *objects):\n",
    "        \"\"\"Find the sets containing the objects and merge them all.\"\"\"\n",
    "        roots = [self[x] for x in objects]\n",
    "        heaviest = max([(self.weights[r],r) for r in roots])[1]\n",
    "        for r in roots:\n",
    "            if r != heaviest:\n",
    "                self.weights[heaviest] += self.weights[r]\n",
    "                self.parents[r] = heaviest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputVec = fceulib.readInputs('movie.fm2')\n",
    "collisions = pickle.load(open('collisions.pkl'))\n",
    "\n",
    "(modes, path, merged, unions, track, all_times) = pickle.load(open(\"modes.pkl\"))\n",
    "\n",
    "# TODO: define axis elsewhere?\n",
    "axis = 2\n",
    "velocities = track[1:,axis]-track[:-1,axis] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = 270\n",
    "transitions = {}\n",
    "# Edges into [outer] from [inner]\n",
    "entries_from = {m: {m: [] for m in merged} \n",
    "                for m in merged}\n",
    "# Edges into [outer]\n",
    "entries = {m: [] for m in merged}\n",
    "for t in range(1,len(path)):\n",
    "    if t == 0:\n",
    "        prev = -1\n",
    "    else:\n",
    "        prev = unions[t-1]\n",
    "    start = path[t][1][0]\n",
    "    entries_from[unions[t]][prev].append(start)\n",
    "    entries[unions[t]].append(start)\n",
    "    transitions[all_times[start]] = (prev,unions[t])\n",
    "    print (start,all_times[start]),\":\",prev,\"->\",unions[t],\"\\n\",path[unions[t]][1][2][0],path[unions[t]][1][2][1].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = nx.MultiDiGraph()\n",
    "for tgt,srcs in entries_from.items():\n",
    "    G.add_node(tgt,label=str(tgt))\n",
    "    # Let's learn about tgt\n",
    "    mtype = path[tgt][1][2][0]\n",
    "    mparams = path[tgt][1][2][1].params\n",
    "    params = {\"type\": mtype}\n",
    "    if mtype == 'c0':\n",
    "        pass\n",
    "    elif mtype == 'cP':\n",
    "        pass\n",
    "    elif mtype == 'cN':\n",
    "        params[\"N\"] = mparams[1]\n",
    "    elif mtype == 'acc0':\n",
    "        params[\"acc\"] = mparams[1]\n",
    "    elif mtype == 'accP':\n",
    "        params[\"acc\"] = mparams[1]\n",
    "    elif mtype == 'accN':\n",
    "        params[\"N\"] = mparams[1]\n",
    "        params[\"acc\"] = mparams[2]\n",
    "    for k,v in params.items():\n",
    "        G.node[tgt][\"label\"] = (G.node[tgt][\"label\"] + \"\\n\" + \"{}: {}\".format(k,v))\n",
    "    print tgt,params\n",
    "    for src,times in srcs.items():\n",
    "        for t in times:\n",
    "            G.add_edge(src,tgt,label=t)\n",
    "\n",
    "G.add_node(-1)\n",
    "G.add_edge(-1, unions[0])\n",
    "\n",
    "m2i = {m:i for i,m in enumerate(merged)}\n",
    "plt.plot(velocities)\n",
    "plt.plot(np.array(all_times),velocities[np.array(all_times,dtype='int')],'rx')\n",
    "for u in sorted(unions):\n",
    "    t0 = all_times[path[u][1][0]]\n",
    "    t1 = all_times[path[u][1][1]]\n",
    "    u_ = m2i[unions[u]]\n",
    "    plt.plot([t0,t1],[unions[u]+10,unions[u]+10])#,colors[u])\n",
    "        \n",
    "plt.xlim((50,100))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "nxpd.draw(G, show='ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def button_changes(button_masks):\n",
    "    last_mask = 0\n",
    "    mask_times = {}\n",
    "    for t, b in enumerate(button_masks):\n",
    "        b_ = int(b)\n",
    "        buttons = []\n",
    "        for ii,c in enumerate(list('RLDUTSBA')):\n",
    "            if b_ & (1 << (7-ii)):\n",
    "                buttons.append(c)\n",
    "        l_ = int(last_mask)\n",
    "        last_buttons = []\n",
    "        for ii,c in enumerate(list('RLDUTSBA')):\n",
    "            if l_ & (1 << (7-ii)):\n",
    "                last_buttons.append(c)\n",
    "        mask_times[t] = (tuple(last_buttons),tuple(buttons))\n",
    "        last_mask = b\n",
    "    \n",
    "    return mask_times\n",
    "\n",
    "button_change_times = button_changes(inputVec)\n",
    "for t in sorted(button_change_times):\n",
    "    print t, button_change_times[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sign(num):\n",
    "    if num < 0:\n",
    "        return -1\n",
    "    if num > 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def button_diff(btnsA, btnsB):\n",
    "    return set(btnsA) - set(btnsB)\n",
    "\n",
    "def button_intersect(btnsA, btnsB):\n",
    "    return set(btnsA) & set(btnsB)\n",
    "\n",
    "def button_union(btnsA, btnsB):\n",
    "    return set(btnsA) | set(btnsB)\n",
    "\n",
    "def button_preds(button_pairs_by_time):\n",
    "    here_i = set()\n",
    "    for bp,off in button_pairs_by_time:\n",
    "        released_i = button_diff(bp[0], bp[1])\n",
    "        pressed_i = button_diff(bp[1], bp[0])    \n",
    "        held_i = bp[1]\n",
    "        for ri in released_i:\n",
    "            here_i.add((\"release\",ri,off))\n",
    "        for ri in pressed_i:\n",
    "            here_i.add((\"press\",ri,off))\n",
    "        for ri in held_i:\n",
    "            here_i.add((\"hold\",ri,off))\n",
    "    return list(here_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = [set()]*len(velocities)\n",
    "for t in range(0,len(velocities)):\n",
    "    psi = ([(button_change_times[start_time+t+i],i)\n",
    "            for i in range(-2, 1)],\n",
    "            #  TODO: stopped colliding/started colliding?  That would mean\n",
    "           #   I could say \"started colliding with X on bottom and also zin,-1\"\n",
    "           #   to help find solid things.\n",
    "           #     ... no... acc,0 should be enough (walking right across solid tiles)\n",
    "           #     but I should also consider \n",
    "           #     a more sophisticated notion of collision.\n",
    "           #      e.g. \"bottom\" is good but it should be the lowest bottom tile.\n",
    "           #      how can I get that?  can I get that?\n",
    "           #      (OTOH, maybe this isn't even necessary if e.g. \"touching my feet against sky\"\n",
    "          #        doesn't cause vy=0 as often as \"touching my feet against ground\" does. so let's be\n",
    "          #         sure that's surfaced!)\n",
    "           # TODO: collisions of previous time and previous previous time also\n",
    "            collisions.get(start_time+t+(0),set()),\n",
    "            (velocities[t-1],velocities[t-0])\n",
    "          )\n",
    "    buttons_i = psi[0]\n",
    "    here_i = button_preds(buttons_i)\n",
    "    for coli in psi[1]:\n",
    "        here_i.append((\"col\",coli))\n",
    "    vel0,vel1 = psi[2]\n",
    "    if vel0 < vel1:\n",
    "        here_i.append((\"acc\",1))\n",
    "    if vel0 > vel1:\n",
    "        here_i.append((\"acc\",-1))\n",
    "    if vel0 == vel1:\n",
    "        here_i.append((\"acc\",0))\n",
    "    if vel1 < 0:\n",
    "        here_i.append((\"vel\",-1))\n",
    "    if vel1 > 0:\n",
    "        here_i.append((\"vel\",1))\n",
    "    if vel1 == 0:\n",
    "        here_i.append((\"vel\",0))\n",
    "    if vel0 < 0 and vel1 > 0:\n",
    "        here_i.append((\"zc\",1))\n",
    "    if vel0 > 0 and vel1 < 0:\n",
    "        here_i.append((\"zc\",-1))\n",
    "    if vel0 < 0 and vel1 == 0:\n",
    "        here_i.append((\"zin\",1))\n",
    "    if vel0 > 0 and vel1 == 0:\n",
    "        here_i.append((\"zin\",-1))\n",
    "    if vel0 == 0 and vel1 < 0:\n",
    "        here_i.append((\"zout\",-1))\n",
    "    if vel0 == 0 and vel1 > 0:\n",
    "        here_i.append((\"zout\",1))\n",
    "    #cur_mode = X\n",
    "    # TODO in_mode X predicate\n",
    "    # TODO: touched global min/max of velocity for current mode\n",
    "    #mode_max = max(velocities_in_cur_mode)\n",
    "    #mode_min = min(velocities_in_cur_mode)\n",
    "    #if vel1 == mode_max and vel0 != mode_max:\n",
    "    #  touched max\n",
    "    #if vel1 == mode_min and vel0 != mode_min:\n",
    "    #  touched min\n",
    "    #if vel1 == mode_max:\n",
    "    #  in min\n",
    "    #if vel1 == mode_min:\n",
    "    #  in max\n",
    "    preds[t] = set(here_i)\n",
    "\n",
    "preds[270+59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: change to include a \"while_in_mode\" argument\n",
    "def count_cooccurrences(pred_sets,ignored):\n",
    "    ocs = {}\n",
    "    coocs = {}\n",
    "    nice_pred_sets = []\n",
    "    for pi in range(0, len(pred_sets)):\n",
    "        here_i = pred_sets[pi]\n",
    "        here_i = list(set(here_i) - ignored)\n",
    "        for pred in here_i:\n",
    "            ocs[pred] = ocs.get(pred,0)+1\n",
    "        for predii in range(0,len(here_i)):\n",
    "            if here_i[predii] not in coocs:\n",
    "                coocs[here_i[predii]] = {}\n",
    "            for predij in range(0,len(here_i)):\n",
    "                coocs[here_i[predii]][here_i[predij]] = coocs[here_i[predii]].get(here_i[predij],0)+1\n",
    "        nice_pred_sets.append(here_i)\n",
    "    return nice_pred_sets,ocs,coocs\n",
    "\n",
    "\n",
    "def calc_npmi(pred_sets, ocs, coocs):\n",
    "    maximum = float(len(pred_sets))\n",
    "    npmis = {}\n",
    "    probs = {}\n",
    "    # How likely are individual predicates to co-occur \n",
    "    #  within the transitions to a given target?\n",
    "    for predx,countx in ocs.items():\n",
    "        px = countx / maximum\n",
    "        probs[predx] = px\n",
    "        for predy,countxy in coocs[predx].items():\n",
    "            py = ocs[predy] / maximum\n",
    "            pxy = countxy / maximum\n",
    "            d = (math.log(px*py)/math.log(pxy) - 1) if pxy != 1 else 1\n",
    "            npmis[(predx,predy)] = d\n",
    "    return probs,npmis\n",
    "\n",
    "def calc_npmi_pred_edge(all_ocs, all_edge_ocs, edge_count, all_edge_count):\n",
    "    npmis = {}\n",
    "    probs = {}\n",
    "    # How likely are individual predicates to co-occur \n",
    "    #  within the transitions to a given target?\n",
    "    for predx,countx in all_ocs.items():\n",
    "        px = countx / float(all_edge_count)\n",
    "        py = edge_count / float(all_edge_count)\n",
    "        pxy = all_edge_ocs.get(predx,0) / float(all_edge_count)\n",
    "        probs[predx] = all_edge_ocs.get(predx,0) / float(edge_count)\n",
    "        assert px <= 1, (px,countx,all_edge_count)\n",
    "        assert py <= 1, (py,edge_count,all_edge_count)\n",
    "        assert pxy <= 1, (pxy,all_edge_ocs.get(predx,0),float(edge_count))\n",
    "        if pxy == 0:\n",
    "            d = -1\n",
    "        elif pxy == 1:\n",
    "            d = 1\n",
    "        else:\n",
    "            d = (math.log(px*py)/math.log(pxy) - 1)\n",
    "        npmis[predx] = d\n",
    "    return probs,npmis\n",
    "\n",
    "def calc_npmi(pred1, pred2, all_counts, counts_by_time):\n",
    "    norm = float(len(counts_by_time)+1)\n",
    "    count1 = all_counts[pred1]\n",
    "    count2 = all_counts[pred2]\n",
    "    count12 = 0\n",
    "    for t,cs in counts_by_time.items():\n",
    "        count12 += cs.get(pred1,0) * cs.get(pred2,0)\n",
    "    p1 = count1 / norm\n",
    "    p2 = count2 / norm\n",
    "    p12 = count12 / norm\n",
    "    if p12 == 0:\n",
    "        d = -1\n",
    "    elif p12 == 1:\n",
    "        d = 1\n",
    "    else:\n",
    "        d = math.log(p1*p2)/math.log(p12) - 1\n",
    "    return d\n",
    "\n",
    "def weight_npmi(npmi, things):\n",
    "    net_weight = 0\n",
    "    WEIGHT_HIGH = 1.00\n",
    "    WEIGHT_MID = 0.75\n",
    "    WEIGHT_NORMAL = 0.50\n",
    "    for t in things:\n",
    "        weight = WEIGHT_NORMAL\n",
    "        type = t[0]\n",
    "        if type == \"tr\" or type == \"press\" or type == \"release\":\n",
    "            weight = WEIGHT_HIGH\n",
    "        elif type == \"hold\" or type == \"col\":\n",
    "            weight = WEIGHT_MID\n",
    "        else:\n",
    "            weight = WEIGHT_NORMAL\n",
    "        net_weight += weight\n",
    "    weight = net_weight / float(len(things))\n",
    "    return (npmi * weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_events(preds):\n",
    "    all_counts = {}\n",
    "    counts_by_time = {}\n",
    "    for t,ps in enumerate(preds):\n",
    "        counts_by_time[t] = {}\n",
    "        for p in ps:\n",
    "            all_counts[p] = all_counts.get(p,0)+1\n",
    "            counts_by_time[t][p] = counts_by_time[t].get(p,0)+1\n",
    "        if t in transitions:\n",
    "            tr = transitions[t]\n",
    "            key = (\"tr\",tr)\n",
    "            all_counts[key] = all_counts.get(key,0)+1\n",
    "            counts_by_time[t][key] = counts_by_time[t].get(key,0)+1\n",
    "            (_,dest) = tr\n",
    "            keystar = (\"tr\",(\"*\",dest))\n",
    "            all_counts[keystar] = all_counts.get(keystar,0)+1\n",
    "            counts_by_time[t][keystar] = counts_by_time[t].get(keystar,0)+1\n",
    "    return all_counts, counts_by_time\n",
    "\n",
    "all_counts,counts_by_time = count_events(preds)\n",
    "all_counts,counts_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's figure out which tiles block movement on which sides!\n",
    "# co-occurrence of (col, BLAH) and acc0 for each BLAH.\n",
    "# cluster together tiles which block on a given side (for now, all those with co-occurrence over threshold)\n",
    "# then add new preds!\n",
    "\n",
    "def cond_prob(e1s, e2, all_counts, counts_by_time):\n",
    "    p2 = all_counts[e2]/float(len(counts_by_time))\n",
    "    count12 = 0\n",
    "    for t,cs in counts_by_time.items():\n",
    "        any_e1_present = False\n",
    "        for e1 in e1s:\n",
    "            if e1 in cs:\n",
    "                any_e1_present = True\n",
    "                break\n",
    "        if any_e1_present and (e2 in cs):\n",
    "            count12 += 1\n",
    "    p12 = count12 / float(len(counts_by_time))\n",
    "    return p12 / p2\n",
    "\n",
    "block_chance = {}\n",
    "for thing,count in all_counts.items():\n",
    "    # TODO: generalize back to all sides, but note \"colliding on right with something\" -> \"vely=0\" is not that sensible.\n",
    "    #  need a notion of acc,vel,zin,zout and _other axis_ acc,vel,zin,zout.\n",
    "    if thing[0] != \"col\": \n",
    "        continue\n",
    "    block_chance[thing] = cond_prob([(\"vel\",0),(\"acc\",0)], \n",
    "                                    thing,\n",
    "                                    all_counts,\n",
    "                                    counts_by_time)\n",
    "\n",
    "merged_by_side = {}\n",
    "# TODO: generalize back to all sides\n",
    "for side in [\"bottom\",\"right\",\"left\",\"top\"]:\n",
    "    # Let's pretend colliding with sprites is the same as colliding with tiles?  Maybe needed for moving platforms?\n",
    "    blockings = filter(lambda (col,prob):(col[1][0][0] != \"solid\" and \n",
    "                                          col[1][1] == side and \n",
    "                                          prob > 0.8),\n",
    "                       block_chance.items())\n",
    "    merged_by_side[side] = set()\n",
    "    for bcol,bprob in blockings:\n",
    "        merged_by_side[side].add(bcol)\n",
    "    merged_by_side[side] = sets.ImmutableSet(merged_by_side[side])\n",
    "        \n",
    "    \n",
    "#color_tiles = pickle.load(open('tile2colorized.pkl'))\n",
    "for side,bcols in merged_by_side.items():\n",
    "    print \"----\\n{}\\n----\".format(side)\n",
    "    for bc in bcols:\n",
    "        print block_chance[bc],bc[1][0]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's add new preds now!\n",
    "new_preds = [set() for i in range(0,len(preds))]\n",
    "for t,pset in enumerate(preds):\n",
    "    for side,equiv in merged_by_side.items():\n",
    "        found = False\n",
    "        for pred in pset:\n",
    "            new_preds[t].add(pred)\n",
    "            if not found and pred[0] == \"col\" and pred in equiv:\n",
    "                new_preds[t].add((\"col\", ((\"solid\", equiv), side)))\n",
    "                found = True\n",
    "all_counts,counts_by_time = count_events(new_preds)\n",
    "\n",
    "\n",
    "all_counts,counts_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's calculate NPMI between predicates and transitions!\n",
    "npmis = {}    \n",
    "for thing,count in all_counts.items():\n",
    "    if thing[0] == \"tr\":\n",
    "        print \"tr:\",thing,count\n",
    "        tr = thing[1]\n",
    "        # Find NPMI with every predicate\n",
    "        for thing2,count in all_counts.items():\n",
    "            if thing2[0] == \"tr\":\n",
    "                continue\n",
    "            if tr not in npmis:\n",
    "                npmis[tr] = {}\n",
    "            npmis[tr][(thing2,)] = weight_npmi(\n",
    "                calc_npmi(thing, \n",
    "                          thing2, \n",
    "                          all_counts,\n",
    "                          counts_by_time),\n",
    "                [thing2]\n",
    "            )\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for tr,prednpmis in npmis.items():\n",
    "    if tr[1] != 5: continue\n",
    "    print \"----\"\n",
    "    print tr\n",
    "    print \"----\"\n",
    "    for pred,pmi in sorted(prednpmis.items(),\n",
    "                           lambda a,b:sign(b[1]-a[1])):\n",
    "        if pmi > 0:\n",
    "            print pred,pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # TODO: this gives different results if e2, e3 in different \n",
    "# #  orders.  Seems wrong!\n",
    "# def calc_npmi_chained(e1,e2,e3,all_counts,counts_by_time):\n",
    "#     p1 = all_counts[e1] / float(len(counts_by_time)+1)\n",
    "#     p2 = all_counts[e2] / float(len(counts_by_time)+1)\n",
    "#     if p1 == 0:\n",
    "#         assert(False)\n",
    "#         print \"p1=0\"\n",
    "#         return -1\n",
    "#     if p2 == 0:\n",
    "#         assert(False)\n",
    "#         print \"p2=0\"\n",
    "#         return -1\n",
    "#     count12 = 0\n",
    "#     for t,cs in counts_by_time.items():\n",
    "#         if (e1 in cs) and (e2 in cs):\n",
    "#             count12 += 1\n",
    "#     p12 = count12 / float(len(counts_by_time)+1)\n",
    "#     if p12 == 0:\n",
    "#         # Never co-occur, avoid log(0)\n",
    "#         return -1\n",
    "#     pmi12 = math.log(p12 / (p1 * p2))\n",
    "#     #p(event ,  causeB| causeA)/ (p(event | causeA) * p(causeB | causeA))\n",
    "#     times_1_and_3_and_2_happen = 0\n",
    "#     times_3_and_2_happen = 0\n",
    "#     times_any_happen = 0\n",
    "#     for t,cs in counts_by_time.items():\n",
    "#         if (e1 in cs) and (e3 in cs) and (e2 in cs):\n",
    "#             times_1_and_3_and_2_happen += 1\n",
    "#         if (e3 in cs) and (e2 in cs):\n",
    "#             times_3_and_2_happen += 1\n",
    "#         if (e1 in cs) or (e2 in cs) or (e3 in cs):\n",
    "#             times_any_happen += 1\n",
    "#     p132 = times_1_and_3_and_2_happen/float(len(counts_by_time)+1)\n",
    "#     if p132 == 0:\n",
    "#         # Never co-occur, avoid log(0)\n",
    "#         return -1\n",
    "#     # TODO: P(x,(z|y)) or P((x,z)|y)?  this looks like the latter.  Because the former makes no sense?\n",
    "#     p13_2 = (p132/p2)\n",
    "#     p32 = times_3_and_2_happen / float(len(counts_by_time)+1)\n",
    "#     p3_2 = p32/p2\n",
    "#     if p13_2 == 0:\n",
    "#         # Never co-occur, avoid log(0)\n",
    "#         return -1\n",
    "#     elif p3_2 == 0:\n",
    "#         # Never co-occur, avoid log(0)\n",
    "#         return -1\n",
    "#     pmi1_23 = math.log(p13_2/(p1 * p3_2))\n",
    "#     # normalize by log(p(event;causeA;causeB))??? no...\n",
    "#     # Normalize by self-information!\n",
    "#     return (pmi12 + pmi1_23)/(2*(-math.log(p132)))\n",
    "\n",
    "# # Let's calculate the NPMI of causal pairs with each transition!\n",
    "# paired_npmis = {}\n",
    "# for thing,count in all_counts.items():\n",
    "#     if thing[0] == \"tr\":\n",
    "#         print \"tr:\",thing,count\n",
    "#         tr = thing[1]\n",
    "#         if tr not in paired_npmis:\n",
    "#             paired_npmis[tr] = {}\n",
    "#         # Find NPMI with every predicate\n",
    "#         for thing2,count2 in all_counts.items():\n",
    "#             if thing2[0] == \"tr\":\n",
    "#                 continue\n",
    "#             for thing3,count3 in all_counts.items():\n",
    "#                 if thing3[0] == \"tr\" or thing3 == thing2:\n",
    "#                     continue\n",
    "#                 key = (thing2,thing3)\n",
    "#                 paired_npmis[tr][key] = weight_npmi(\n",
    "#                     calc_npmi_chained(thing,\n",
    "#                                       thing2,\n",
    "#                                       thing3,\n",
    "#                                       all_counts,\n",
    "#                                       counts_by_time),\n",
    "#                     [thing2,thing3]\n",
    "#                 )\n",
    "#         print \"\\n\".join(\n",
    "#             map(str,\n",
    "#                 sorted(filter(\n",
    "#                         lambda (k,v): v > 0,\n",
    "#                         paired_npmis[tr].items()),\n",
    "#                        lambda a,b:sign(b[1]-a[1]))))\n",
    "        \n",
    "#     else:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevance_threshold = 0.1\n",
    "universality_threshold = 0.8\n",
    "negation_threshold = -1.0\n",
    "\n",
    "for tr,pred_npmis in npmis.items():# + paired_npmis.items():\n",
    "    if tr[1] != 5: continue\n",
    "\n",
    "    cond_probs = {k: cond_prob(list(k), (\"tr\",tr), all_counts, counts_by_time) for k in pred_npmis.keys()}\n",
    "    relevants = {k: npmi for (k,npmi) in pred_npmis.items() if npmi >= relevance_threshold}\n",
    "    negations = {k: npmi for (k,npmi) in pred_npmis.items() if npmi <= negation_threshold}\n",
    "    conjuncts = set(filter(lambda k:cond_probs[k] >= universality_threshold, relevants.keys()))\n",
    "    disjuncts = set(filter(lambda k:cond_probs[k] < universality_threshold, relevants.keys()))\n",
    "    print \"-------\\nTransition:\",tr\n",
    "    print \"\\n\".join(map(str,cond_probs.items()))\n",
    "    print \"-----\\nRelevant:\\n\",\"\\n\".join(map(str,relevants.items()))\n",
    "    print \"-----\\nConjuncts:\\n\",\" & \".join(map(str,conjuncts))\n",
    "    print \"-----\\nDisjuncts:\\n\",\" | \".join(map(str,disjuncts))\n",
    "    print \"-----\\nNegations:\\n\",\" & \".join(map(lambda k:\"~\" + str(k),negations))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump((npmis, entries, entries_from, new_preds, modes, merged, unions, track, inputVec, all_times), \n",
    "            open(\"edges.pkl\",'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
